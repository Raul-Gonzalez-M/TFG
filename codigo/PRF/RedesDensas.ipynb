{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')\n",
    "print(\"Dispositivos tras deshabilitar GPUs:\", tf.config.get_visible_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SolAtasIMC_tratado.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanio = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.copy().loc[0:int(tamanio*0.7)]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vali = df.copy().loc[int(tamanio*0.7 + 1):int(tamanio*0.9)]\n",
    "df_vali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy().loc[int(tamanio*0.9 + 1):tamanio]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valitest = pd.concat([df_vali, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numero de horas que se utilizan en la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numhorasconst = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales Densas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"¿GPU detectada?:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Versión de TensorFlow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        X.append(data[i:i+n_steps])     # Añado a X las listaa de listas de precios \n",
    "        y.append(data[i+n_steps, 3])    # Añado a y el precio de cierre de la siguiente hora  \n",
    "    return np.array(X), np.array(y)     # Los transformo en arrays de numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_datos(df, numhoras):\n",
    "    data = df[['open', 'high', 'low', 'close', 'value']].values # Selecciono y transformo las columnas del dataframe en un array\n",
    "    # Genero una matriz de listas, cada entrada de la matriz contiene n listas del tipo [open, high, low, close, value] siendo n = numhoras\n",
    "    X, y = create_sequences(data, numhoras) \n",
    "    X_aux = []\n",
    "    for i in X: # Tansformo la matriz de listas en una lista de listas, juntando las n listas de cada entrada en una\n",
    "        aux = []\n",
    "        for r in range(0, numhoras): # Transformo las n listas de esa entrada en una\n",
    "            for elem in i[r]:\n",
    "                aux.append(elem)\n",
    "        X_aux.append(aux)   # Añado la lista transformada a la lista global\n",
    "    X_aux = np.array(X_aux) # Transformo la lista en un array de numpy\n",
    "    return X_aux, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalRedDensa(ytest, y_pred):\n",
    "    y_pred = y_pred.flatten()   # Transforma una lista de listas en una lista de valores\n",
    "    suma = 0\n",
    "    n = len(y_pred)     # Obtengo el tamaño de y\n",
    "    for i in range(0,n):    # Suma el error relativo de todas las predicciones\n",
    "        suma = abs(y_pred[i] - ytest[i])/ytest[i] +  suma\n",
    "    error_medio = suma/n    # Divido la suma entre el número de predicciones para calcular la media\n",
    "    emp = error_medio*100   # Multiplico por 100 para obtener el error porcentual medio\n",
    "    return emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy() # Replica tu modelo en todas las GPUs disponibles\n",
    "print(f\"Número de GPUs detectadas: {strategy.num_replicas_in_sync}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opti_redes_densas_multi_gpu(epoch_array, batch_array, numhoras, X_train, y_train, X_vali, y_vali, X_test, y_test):\n",
    "    best = float('inf') # Asigno a best un valor infinito de tipo float\n",
    "    epoch_best = 0\n",
    "    bacth_best = 0\n",
    "    best_model = None\n",
    "    training_results = []\n",
    "\n",
    "    for e in epoch_array:   # Genero modelos con todos los epoch pasados como parámetro en el array\n",
    "        for b in batch_array:   # Genero modelos con todos los batch_size pasados como parámetro en el array\n",
    "            best_value_of_the15 = float('inf')  # Asigno a best_value_of_the25 un valor infinito de tipo float\n",
    "            best_model_of_the15 = None\n",
    "            with tf.device('/CPU:0'):\n",
    "                for m in range(15): # Genero 15 modelos con cada de par epoch, bacth_size \n",
    "                    with strategy.scope():  # El código debajo de esta línea se ejecuta usando la estrategia que hay en el scope\n",
    "                        model = Sequential()    # Declaro el modelo como secuencial\n",
    "                        # Creo la capa de entrada con 128 neuronas, definiendo la forma de la entrada y y cuya función de activacion es Rectified Linear Unit\n",
    "                        model.add(Dense(128, activation='relu', input_shape=(numhoras * 5,)))   \n",
    "                        # Creo la capa interna con 64 neuronas y cuya función de activacion es Rectified Linear Unit, que selecciona el másximo entre 0 y el valor de la neurona\n",
    "                        model.add(Dense(64, activation='relu'))\n",
    "                        # Creo la capa de salida \n",
    "                        model.add(Dense(1))\n",
    "                        # Compilo la red neuronal usando adam como optimizador y mape, Mean Absolute Percentage Error, como función que debe minimizar\n",
    "                        model.compile(optimizer='adam', loss='mape')\n",
    "\n",
    "                        history = model.fit(X_train, y_train, epochs=e, batch_size=b, validation_data=(X_vali, y_vali), shuffle=False)  # Entreno el modelo\n",
    "                    y_pred = model.predict(X_test)  # Realizo una predicción usando los datos de test\n",
    "                    valor = evalRedDensa(y_test, y_pred) # Evalúo el rendimiento del modelo\n",
    "\n",
    "                    if valor < best_value_of_the15: # Si el rendimiento que obtengo es el mejor de esta iteración hasta ahora lo sustituyo y guardo el modelo\n",
    "                        best_value_of_the15 = valor\n",
    "                        best_model_of_the15 = model\n",
    "\n",
    "                print(f\"Epoch: {e}, Batch size: {b}, Value: {best_value_of_the15}\") # Imprimo por pantalla la epoch, el batch_size y el mejor rendimiento obtenido para estos\n",
    "                \n",
    "                training_results.append({\"epoch\": e, # Guardo la información de la epoch, el batch_size, el numero de horas y el mejor rendimiento obtenido para estos\n",
    "                                        \"batch_size\": b, \n",
    "                                        \"hours\": numhoras, \n",
    "                                        \"value\": best_value_of_the15})  \n",
    "                \n",
    "            with open('pasosdados.txt', 'w') as archivo:   \n",
    "                archivo.write(\"epoch: \"+str(e)+\", batch_size:\" + str(b))    # Escribo en un archivo de texto la epoch y el batch_size para los que acabo de entrenar el modelo\n",
    "            if best_value_of_the15 < best:   # Si el rendimiento que he obtenido en la iteración es el mejor hasta ahora lo sustituyo \n",
    "                best = best_value_of_the15\n",
    "                epoch_best = e  # Guardo su epoch\n",
    "                bacth_best = b  # Guardo su batch_size\n",
    "                best_model = best_model_of_the15    # Guardo el modelo en la variable\n",
    "                if best < 0.75: # Si el rendimiento es mejor que 0,75, guardo el modelo\n",
    "                    cadena_guardado = f\"ModelosDensosOptiMultiGPUIMC/mi_modelo_densoIMC_Opti_e{e}_b{b}_v{round(best, 3)}_nh{numhoras}\"\n",
    "                    best_model.save(cadena_guardado + \".keras\") # Guardo el modelo\n",
    "\n",
    "    results_df = pd.DataFrame(training_results) # Transformo los datos guardados en un dataframe\n",
    "    cadena = \"desnsasH\" + str(numhoras) + \".csv\"\n",
    "    results_df.to_csv(cadena, index=False)  # Guardo el dataframe con formato csv\n",
    "    print(\"Resultados guardados en 'densas.csv'\")   # Imprimo por pantalla un mensaje que indica que el dataframe ha sido guardado\n",
    "    return epoch_best, bacth_best, best, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opti_rd_h(h_array, epoch_array, batch_array):\n",
    "    best = float('inf') # Asigno a best un valor infinito de tipo float\n",
    "    epoch_best = 0\n",
    "    bacth_best = 0\n",
    "    h_best = 0\n",
    "    best_model = None\n",
    "    for i in h_array:   # Entreno modelos con el numero de horas en el array de horas\n",
    "        Xtrain, ytrain = preparar_datos(df_train, i)    # Preparo los datos de entrenamiento\n",
    "        Xvali, yvali = preparar_datos(df_vali, i)   # Preparo los datos de validación\n",
    "        Xtest, ytest = preparar_datos(df_test, i)   # Preparo los datos de test\n",
    "        # Entreno los modelos usando los datos preparados con la cantidad de horas correcta\n",
    "        valores = opti_redes_densas_multi_gpu(epoch_array, batch_array, i, Xtrain, ytrain, Xvali, yvali, Xtest, ytest)\n",
    "        if valores[2] < best:   # Si el rendimiento que he obtenido en la iteración es el mejor hasta ahora lo sustituyo \n",
    "            best = valores[2]\n",
    "            epoch_best = valores[0] # Guardo su epoch\n",
    "            bacth_best = valores[1] # Guardo su batch_size\n",
    "            h_best = i  # Guardo el número de horas\n",
    "            best_model = valores[3] # Guardo el modelo en la variable\n",
    "            cadena_guardado = \"ModelosDensosOptiMoreDataIMCBest/mi_modelo_densoIMC_Opti_e\"+str(epoch_best)+\"_b\"+str(bacth_best)+\"_h\"+str(i)+\"_v\"+str(round(best, 3))+\"_nh\"+str(i)\n",
    "            best_model.save(cadena_guardado+\".keras\")   # Guardo el modelo\n",
    "        with open('pasosdadoshoras.txt', 'w') as archivo:   \n",
    "            archivo.write(\"horas: \"+str(i)+\"\\n\")    # Escribo en un archivo de texto la hora para la que acabo de entrenar los modelos\n",
    "    return best, epoch_best, bacth_best, h_best, best_model # Devuelvo el mejor rendimiento, epoch, batch_size, hora y modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamo a la función de entrenamiento principal, la primera es la lista con las horas, al segunda es la lista con las epoch y la tercera es la lista de los batch_size\n",
    "data = opti_rd_h([1, 3, 5, 7, 10, 12, 14, 18, 21], [4, 6, 10, 14, 20, 40], [4, 8, 12, 16, 32, 64, 128, 256])\n",
    "print(data) # Imprimo lo que devuelve la función\n",
    "print(\"Ha terminado\")   # Imprimo un mensaje indicando que la ejecución ha concluido"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
