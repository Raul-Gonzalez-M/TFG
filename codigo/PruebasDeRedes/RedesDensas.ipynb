{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivos tras deshabilitar GPUs: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')\n",
    "print(\"Dispositivos tras deshabilitar GPUs:\", tf.config.get_visible_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-12 03:00:00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.25</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-12 04:00:00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.15</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-12 05:00:00</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.30</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-12 06:00:00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.30</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-12 07:00:00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  open  high   low  close  value\n",
       "0  2020-08-12 03:00:00  3.10  3.35  3.10   3.25     75\n",
       "1  2020-08-12 04:00:00  3.25  3.25  3.15   3.15     75\n",
       "2  2020-08-12 05:00:00  3.15  3.30  3.15   3.30     75\n",
       "3  2020-08-12 06:00:00  3.30  3.30  3.15   3.30     75\n",
       "4  2020-08-12 07:00:00  3.25  3.25  3.20   3.25     75"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SolAtasIMC_tratado.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36400 entries, 0 to 36399\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   date    36400 non-null  object \n",
      " 1   open    36400 non-null  float64\n",
      " 2   high    36400 non-null  float64\n",
      " 3   low     36400 non-null  float64\n",
      " 4   close   36400 non-null  float64\n",
      " 5   value   36400 non-null  int64  \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanio = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-12 03:00:00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.25</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-12 04:00:00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.15</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-12 05:00:00</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.30</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-12 06:00:00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.30</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-12 07:00:00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25476</th>\n",
       "      <td>2023-07-11 21:00:00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.05</td>\n",
       "      <td>21.90</td>\n",
       "      <td>22.00</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25477</th>\n",
       "      <td>2023-07-11 22:00:00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.10</td>\n",
       "      <td>21.90</td>\n",
       "      <td>22.00</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25478</th>\n",
       "      <td>2023-07-11 23:00:00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.05</td>\n",
       "      <td>21.75</td>\n",
       "      <td>21.95</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25479</th>\n",
       "      <td>2023-07-12 00:00:00</td>\n",
       "      <td>21.95</td>\n",
       "      <td>22.10</td>\n",
       "      <td>21.90</td>\n",
       "      <td>22.05</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25480</th>\n",
       "      <td>2023-07-12 01:00:00</td>\n",
       "      <td>22.05</td>\n",
       "      <td>22.15</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.10</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25481 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date   open   high    low  close  value\n",
       "0      2020-08-12 03:00:00   3.10   3.35   3.10   3.25     75\n",
       "1      2020-08-12 04:00:00   3.25   3.25   3.15   3.15     75\n",
       "2      2020-08-12 05:00:00   3.15   3.30   3.15   3.30     75\n",
       "3      2020-08-12 06:00:00   3.30   3.30   3.15   3.30     75\n",
       "4      2020-08-12 07:00:00   3.25   3.25   3.20   3.25     75\n",
       "...                    ...    ...    ...    ...    ...    ...\n",
       "25476  2023-07-11 21:00:00  22.00  22.05  21.90  22.00     57\n",
       "25477  2023-07-11 22:00:00  22.00  22.10  21.90  22.00     57\n",
       "25478  2023-07-11 23:00:00  22.00  22.05  21.75  21.95     57\n",
       "25479  2023-07-12 00:00:00  21.95  22.10  21.90  22.05     64\n",
       "25480  2023-07-12 01:00:00  22.05  22.15  22.00  22.10     64\n",
       "\n",
       "[25481 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.copy().loc[0:int(tamanio*0.7)]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25481</th>\n",
       "      <td>2023-07-12 02:00:00</td>\n",
       "      <td>22.10</td>\n",
       "      <td>22.30</td>\n",
       "      <td>22.05</td>\n",
       "      <td>22.15</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482</th>\n",
       "      <td>2023-07-12 03:00:00</td>\n",
       "      <td>22.15</td>\n",
       "      <td>22.25</td>\n",
       "      <td>22.10</td>\n",
       "      <td>22.10</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25483</th>\n",
       "      <td>2023-07-12 04:00:00</td>\n",
       "      <td>22.10</td>\n",
       "      <td>22.10</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25484</th>\n",
       "      <td>2023-07-12 05:00:00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>21.90</td>\n",
       "      <td>21.95</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25485</th>\n",
       "      <td>2023-07-12 06:00:00</td>\n",
       "      <td>21.95</td>\n",
       "      <td>22.05</td>\n",
       "      <td>21.90</td>\n",
       "      <td>22.00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32756</th>\n",
       "      <td>2024-05-10 05:00:00</td>\n",
       "      <td>153.65</td>\n",
       "      <td>154.35</td>\n",
       "      <td>152.85</td>\n",
       "      <td>153.95</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32757</th>\n",
       "      <td>2024-05-10 06:00:00</td>\n",
       "      <td>153.95</td>\n",
       "      <td>154.70</td>\n",
       "      <td>153.45</td>\n",
       "      <td>153.75</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32758</th>\n",
       "      <td>2024-05-10 07:00:00</td>\n",
       "      <td>153.75</td>\n",
       "      <td>154.10</td>\n",
       "      <td>152.30</td>\n",
       "      <td>153.30</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32759</th>\n",
       "      <td>2024-05-10 08:00:00</td>\n",
       "      <td>153.30</td>\n",
       "      <td>155.10</td>\n",
       "      <td>153.15</td>\n",
       "      <td>154.95</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32760</th>\n",
       "      <td>2024-05-10 09:00:00</td>\n",
       "      <td>154.95</td>\n",
       "      <td>155.75</td>\n",
       "      <td>154.25</td>\n",
       "      <td>154.35</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7280 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date    open    high     low   close  value\n",
       "25481  2023-07-12 02:00:00   22.10   22.30   22.05   22.15     64\n",
       "25482  2023-07-12 03:00:00   22.15   22.25   22.10   22.10     64\n",
       "25483  2023-07-12 04:00:00   22.10   22.10   22.00   22.00     64\n",
       "25484  2023-07-12 05:00:00   22.00   22.00   21.90   21.95     64\n",
       "25485  2023-07-12 06:00:00   21.95   22.05   21.90   22.00     64\n",
       "...                    ...     ...     ...     ...     ...    ...\n",
       "32756  2024-05-10 05:00:00  153.65  154.35  152.85  153.95     66\n",
       "32757  2024-05-10 06:00:00  153.95  154.70  153.45  153.75     66\n",
       "32758  2024-05-10 07:00:00  153.75  154.10  152.30  153.30     66\n",
       "32759  2024-05-10 08:00:00  153.30  155.10  153.15  154.95     66\n",
       "32760  2024-05-10 09:00:00  154.95  155.75  154.25  154.35     66\n",
       "\n",
       "[7280 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vali = df.copy().loc[int(tamanio*0.7 + 1):int(tamanio*0.9)]\n",
    "df_vali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32761</th>\n",
       "      <td>2024-05-10 10:00:00</td>\n",
       "      <td>154.35</td>\n",
       "      <td>154.5</td>\n",
       "      <td>153.45</td>\n",
       "      <td>154.10</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32762</th>\n",
       "      <td>2024-05-10 11:00:00</td>\n",
       "      <td>154.10</td>\n",
       "      <td>154.8</td>\n",
       "      <td>153.25</td>\n",
       "      <td>154.15</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32763</th>\n",
       "      <td>2024-05-10 12:00:00</td>\n",
       "      <td>154.15</td>\n",
       "      <td>154.3</td>\n",
       "      <td>153.25</td>\n",
       "      <td>154.15</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32764</th>\n",
       "      <td>2024-05-10 13:00:00</td>\n",
       "      <td>154.15</td>\n",
       "      <td>155.2</td>\n",
       "      <td>153.00</td>\n",
       "      <td>155.05</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32765</th>\n",
       "      <td>2024-05-10 14:00:00</td>\n",
       "      <td>155.05</td>\n",
       "      <td>155.4</td>\n",
       "      <td>153.10</td>\n",
       "      <td>153.30</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36395</th>\n",
       "      <td>2024-10-08 20:00:00</td>\n",
       "      <td>143.35</td>\n",
       "      <td>143.9</td>\n",
       "      <td>142.35</td>\n",
       "      <td>142.95</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36396</th>\n",
       "      <td>2024-10-08 21:00:00</td>\n",
       "      <td>142.95</td>\n",
       "      <td>144.1</td>\n",
       "      <td>142.25</td>\n",
       "      <td>143.75</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36397</th>\n",
       "      <td>2024-10-08 22:00:00</td>\n",
       "      <td>143.75</td>\n",
       "      <td>144.5</td>\n",
       "      <td>143.35</td>\n",
       "      <td>144.50</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36398</th>\n",
       "      <td>2024-10-08 23:00:00</td>\n",
       "      <td>144.50</td>\n",
       "      <td>144.7</td>\n",
       "      <td>144.05</td>\n",
       "      <td>144.25</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36399</th>\n",
       "      <td>2024-10-09 00:00:00</td>\n",
       "      <td>144.25</td>\n",
       "      <td>144.3</td>\n",
       "      <td>143.55</td>\n",
       "      <td>143.80</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3639 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date    open   high     low   close  value\n",
       "32761  2024-05-10 10:00:00  154.35  154.5  153.45  154.10     66\n",
       "32762  2024-05-10 11:00:00  154.10  154.8  153.25  154.15     66\n",
       "32763  2024-05-10 12:00:00  154.15  154.3  153.25  154.15     66\n",
       "32764  2024-05-10 13:00:00  154.15  155.2  153.00  155.05     66\n",
       "32765  2024-05-10 14:00:00  155.05  155.4  153.10  153.30     66\n",
       "...                    ...     ...    ...     ...     ...    ...\n",
       "36395  2024-10-08 20:00:00  143.35  143.9  142.35  142.95     49\n",
       "36396  2024-10-08 21:00:00  142.95  144.1  142.25  143.75     49\n",
       "36397  2024-10-08 22:00:00  143.75  144.5  143.35  144.50     49\n",
       "36398  2024-10-08 23:00:00  144.50  144.7  144.05  144.25     49\n",
       "36399  2024-10-09 00:00:00  144.25  144.3  143.55  143.80     49\n",
       "\n",
       "[3639 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df.copy().loc[int(tamanio*0.9 + 1):tamanio]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valitest = pd.concat([df_vali, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numero de horas que se utilizan en la predicciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numhorasconst = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales Densas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â¿GPU detectada?: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Â¿GPU detectada?:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VersiÃ³n de TensorFlow: 2.10.1\n"
     ]
    }
   ],
   "source": [
    "print(\"VersiÃ³n de TensorFlow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        X.append(data[i:i+n_steps])\n",
    "        y.append(data[i+n_steps, 3])  \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_datos(df, numhoras):\n",
    "    data = df[['open', 'high', 'low', 'close', 'value']].values\n",
    "    X, y = create_sequences(data, numhoras)\n",
    "    X_aux = []\n",
    "    for i in X:\n",
    "        aux = []\n",
    "        for r in range(0, numhoras):\n",
    "            for elem in i[r]:\n",
    "                aux.append(elem)\n",
    "        X_aux.append(aux)       \n",
    "    X_aux = np.array(X_aux) \n",
    "    return X_aux, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalRedDensa(ytest, y_pred):\n",
    "    y_pred = y_pred.flatten()\n",
    "    suma = 0\n",
    "    n = len(y_pred)\n",
    "    for i in range(0,n):\n",
    "        suma = abs(y_pred[i] - ytest[i])/ytest[i] +  suma\n",
    "    error_medio = suma/n\n",
    "    emp = error_medio*100 # error medio en porcentaje\n",
    "    return emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "NÃºmero de GPUs detectadas: 1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(f\"NÃºmero de GPUs detectadas: {strategy.num_replicas_in_sync}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opti_redes_densas_multi_gpu(epoch_ini, epoch_fin, batch_array, numhoras, X_train, y_train, X_vali, y_vali, X_test, y_test):\n",
    "    best = 100\n",
    "    epoch_best = 0\n",
    "    bacth_best = 0\n",
    "    best_model = None\n",
    "    training_results = []\n",
    "\n",
    "    for e in range(epoch_ini, epoch_fin + 1):\n",
    "        for b in batch_array:\n",
    "            best_value_of_the25 = 100\n",
    "            best_model_of_the25 = None\n",
    "            with tf.device('/CPU:0'):\n",
    "                seguir = True\n",
    "                m = 0\n",
    "                w = 0\n",
    "                while(m < 25 and seguir):  # NÃºmero de veces que se entrena cada modelo\n",
    "                    with strategy.scope():\n",
    "                        model = Sequential()\n",
    "                        model.add(Dense(64, activation='relu', input_shape=(numhoras * 5,)))\n",
    "                        #for _ in range(150):\n",
    "                        model.add(Dense(64, activation='relu'))\n",
    "                        model.add(Dense(1))\n",
    "                        model.compile(optimizer='adam', loss='mape')\n",
    "\n",
    "                        history = model.fit(X_train, y_train, epochs=e, batch_size=b, validation_data=(X_vali, y_vali), shuffle=False)\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    valor = evalRedDensa(y_test, y_pred)\n",
    "\n",
    "                    if valor < best_value_of_the25:\n",
    "                        best_value_of_the25 = valor\n",
    "                        best_model_of_the25 = model\n",
    "                    m += 1\n",
    "                    if valor > 3:\n",
    "                        w += 1\n",
    "                    if w > 2:\n",
    "                        seguir =  False\n",
    "\n",
    "            print(f\"Epoch: {e}, Batch size: {b}, Value: {best_value_of_the25}\")\n",
    "            \n",
    "            training_results.append({\"epoch\": e, \n",
    "                                      \"batch_size\": b, \n",
    "                                      \"hours\": numhoras, \n",
    "                                      \"value\": best_value_of_the25})\n",
    "            \n",
    "            with open('pasosdados.txt', 'w') as archivo:\n",
    "                archivo.write(\"epoch: \"+str(e)+\", batch_size:\" + str(b))\n",
    "\n",
    "            if best_value_of_the25 < best:\n",
    "                best = best_value_of_the25\n",
    "                epoch_best = e\n",
    "                bacth_best = b\n",
    "                if best < 1.5:\n",
    "                    cadena_guardado = f\"ModelosDensosOptiMultiGPU/mi_modelo_denso_Opti_e{e}_b{b}_v{round(best_value_of_the25, 3)}_nh{numhoras}\"\n",
    "                    best_model_of_the25.save(cadena_guardado + \".h5\")\n",
    "                    best_model_of_the25.save(cadena_guardado + \".keras\")\n",
    "                best_model = best_model_of_the25\n",
    "    results_df = pd.DataFrame(training_results)\n",
    "    results_df.to_csv(\"densas.csv\", index=False)\n",
    "    print(\"Resultados guardados en 'densas.csv'\")\n",
    "    return epoch_best, bacth_best, best, best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opti_rd_h(inih, finh, epoch_ini, epoch_fin, batch_array):\n",
    "    best = 100\n",
    "    epoch_best = 0\n",
    "    bacth_best = 0\n",
    "    h_best = 0\n",
    "    best_model = None\n",
    "    for i in range(inih, finh+1):\n",
    "        Xtrain, ytrain = preparar_datos(df_train, i)\n",
    "        Xvali, yvali = preparar_datos(df_vali, i)\n",
    "        Xtest, ytest = preparar_datos(df_test, i)\n",
    "        valores = opti_redes_densas_multi_gpu(epoch_ini, epoch_fin, batch_array, i, Xtrain, ytrain, Xvali, yvali, Xtest, ytest)\n",
    "        if valores[2] < best:\n",
    "            best = valores[2]\n",
    "            epoch_best = valores[0]\n",
    "            bacth_best = valores[1]\n",
    "            h_best = i\n",
    "            best_model = valores[3]\n",
    "            cadena_guardado = \"ModelosDensosOptiMoreDataIMCBest/mi_modelo_denso_Opti_e\"+str(epoch_best)+\"_b\"+str(bacth_best)+\"_h\"+str(i)+\"_v\"+str(round(best, 3)+\"_nh\"+str(i))\n",
    "            best_model.save(cadena_guardado+\".h5\")\n",
    "            best_model.save(cadena_guardado+\".keras\")\n",
    "        with open('pasosdadoshoras.txt', 'w') as archivo:\n",
    "            archivo.write(\"horas: \"+str(i)+\"\\n\")\n",
    "    return best, epoch_best, bacth_best, h_best, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6369/6369 [==============================] - 11s 1ms/step - loss: 6.3774 - val_loss: 12.2701\n",
      "Epoch 2/3\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.7032 - val_loss: 11.4840\n",
      "Epoch 3/3\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.2665 - val_loss: 9.2832\n",
      "114/114 [==============================] - 1s 726us/step\n",
      "Epoch 1/3\n",
      "6369/6369 [==============================] - 11s 1ms/step - loss: 7.0856 - val_loss: 17.8315\n",
      "Epoch 2/3\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.9796 - val_loss: 7.0480\n",
      "Epoch 3/3\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.7589 - val_loss: 6.3091\n",
      "114/114 [==============================] - 1s 912us/step\n",
      "Epoch 1/3\n",
      "6369/6369 [==============================] - 10s 1ms/step - loss: 6.8566 - val_loss: 21.5628\n",
      "Epoch 2/3\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.6854 - val_loss: 10.4288\n",
      "Epoch 3/3\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.1450 - val_loss: 6.8703\n",
      "114/114 [==============================] - 1s 735us/step\n",
      "Epoch: 3, Batch size: 4, Value: 10.367222137645497\n",
      "Epoch 1/3\n",
      "4246/4246 [==============================] - 8s 1ms/step - loss: 7.1852 - val_loss: 23.6976\n",
      "Epoch 2/3\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 4.9129 - val_loss: 12.9338\n",
      "Epoch 3/3\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.2889 - val_loss: 5.7194\n",
      "114/114 [==============================] - 1s 726us/step\n",
      "Epoch 1/3\n",
      "4246/4246 [==============================] - 8s 1ms/step - loss: 8.8188 - val_loss: 18.7278\n",
      "Epoch 2/3\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 4.7851 - val_loss: 8.5656\n",
      "Epoch 3/3\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.1842 - val_loss: 3.0796\n",
      "114/114 [==============================] - 1s 779us/step\n",
      "Epoch 1/3\n",
      "4246/4246 [==============================] - 8s 1ms/step - loss: 9.3182 - val_loss: 32.9940\n",
      "Epoch 2/3\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 6.9888 - val_loss: 16.3137\n",
      "Epoch 3/3\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.7278 - val_loss: 5.8279\n",
      "114/114 [==============================] - 0s 805us/step\n",
      "Epoch: 3, Batch size: 6, Value: 3.5840250580259565\n",
      "Epoch 1/3\n",
      "3185/3185 [==============================] - 7s 1ms/step - loss: 6.2204 - val_loss: 18.0432\n",
      "Epoch 2/3\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 5.9971 - val_loss: 11.4151\n",
      "Epoch 3/3\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.2311 - val_loss: 4.1707\n",
      "114/114 [==============================] - 1s 796us/step\n",
      "Epoch 1/3\n",
      "3185/3185 [==============================] - 7s 1ms/step - loss: 6.7965 - val_loss: 16.2689\n",
      "Epoch 2/3\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.7739 - val_loss: 5.8683\n",
      "Epoch 3/3\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.2352 - val_loss: 6.4305\n",
      "114/114 [==============================] - 1s 752us/step\n",
      "Epoch 1/3\n",
      "3185/3185 [==============================] - 6s 1ms/step - loss: 8.0176 - val_loss: 14.7507\n",
      "Epoch 2/3\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 6.1276 - val_loss: 6.9121\n",
      "Epoch 3/3\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.1843 - val_loss: 4.8870\n",
      "114/114 [==============================] - 1s 973us/step\n",
      "Epoch: 3, Batch size: 8, Value: 6.701396130564125\n",
      "Epoch 1/3\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 7.9268 - val_loss: 18.9074\n",
      "Epoch 2/3\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 6.7253 - val_loss: 12.2531\n",
      "Epoch 3/3\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 4.1557 - val_loss: 9.0997\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch 1/3\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 10.6120 - val_loss: 22.2167\n",
      "Epoch 2/3\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 8.5110 - val_loss: 13.5421\n",
      "Epoch 3/3\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 5.4255 - val_loss: 12.8456\n",
      "114/114 [==============================] - 1s 858us/step\n",
      "Epoch 1/3\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 9.8689 - val_loss: 12.9389\n",
      "Epoch 2/3\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 6.2690 - val_loss: 8.6477\n",
      "Epoch 3/3\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 4.6291 - val_loss: 7.2215\n",
      "114/114 [==============================] - 1s 831us/step\n",
      "Epoch: 3, Batch size: 12, Value: 12.321536209279975\n",
      "Epoch 1/3\n",
      "1593/1593 [==============================] - 6s 2ms/step - loss: 8.4695 - val_loss: 13.1400\n",
      "Epoch 2/3\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 8.4134 - val_loss: 7.0177\n",
      "Epoch 3/3\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.7761 - val_loss: 5.8599\n",
      "114/114 [==============================] - 1s 752us/step\n",
      "Epoch 1/3\n",
      "1593/1593 [==============================] - 5s 2ms/step - loss: 8.4419 - val_loss: 19.0588\n",
      "Epoch 2/3\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 8.4998 - val_loss: 13.1805\n",
      "Epoch 3/3\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 5.1877 - val_loss: 9.9221\n",
      "114/114 [==============================] - 1s 779us/step\n",
      "Epoch 1/3\n",
      "1593/1593 [==============================] - 5s 2ms/step - loss: 13.6148 - val_loss: 21.3159\n",
      "Epoch 2/3\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 9.8950 - val_loss: 11.0196\n",
      "Epoch 3/3\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 6.2377 - val_loss: 10.6768\n",
      "114/114 [==============================] - 1s 690us/step\n",
      "Epoch: 3, Batch size: 16, Value: 7.223451434730889\n",
      "Epoch 1/3\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 8.4669 - val_loss: 2.6972\n",
      "Epoch 2/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 9.2163 - val_loss: 3.0617\n",
      "Epoch 3/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 6.9055 - val_loss: 1.6227\n",
      "114/114 [==============================] - 1s 708us/step\n",
      "Epoch 1/3\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 9.4752 - val_loss: 3.9495\n",
      "Epoch 2/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 8.6853 - val_loss: 1.7408\n",
      "Epoch 3/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.4170 - val_loss: 1.4715\n",
      "114/114 [==============================] - 1s 796us/step\n",
      "Epoch 1/3\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 15.6975 - val_loss: 3.4732\n",
      "Epoch 2/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 12.0851 - val_loss: 4.5720\n",
      "Epoch 3/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 8.2125 - val_loss: 1.5089\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch 1/3\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 12.3067 - val_loss: 8.4340\n",
      "Epoch 2/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 15.2638 - val_loss: 3.1365\n",
      "Epoch 3/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.3436 - val_loss: 5.5132\n",
      "114/114 [==============================] - 1s 717us/step\n",
      "Epoch 1/3\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 6.4726 - val_loss: 10.3207\n",
      "Epoch 2/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 8.3623 - val_loss: 7.0841\n",
      "Epoch 3/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.7827 - val_loss: 7.7790\n",
      "114/114 [==============================] - 2s 832us/step\n",
      "Epoch 1/3\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 9.3673 - val_loss: 6.3354\n",
      "Epoch 2/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 10.2899 - val_loss: 1.8474\n",
      "Epoch 3/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 9.9185 - val_loss: 2.3543\n",
      "114/114 [==============================] - 1s 814us/step\n",
      "Epoch 1/3\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 11.6447 - val_loss: 8.2563\n",
      "Epoch 2/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.7809 - val_loss: 3.9333\n",
      "Epoch 3/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 6.8812 - val_loss: 2.1015\n",
      "114/114 [==============================] - 1s 735us/step\n",
      "Epoch 1/3\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 12.1156 - val_loss: 9.8738\n",
      "Epoch 2/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 12.0920 - val_loss: 14.4904\n",
      "Epoch 3/3\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 9.0424 - val_loss: 10.5839\n",
      "114/114 [==============================] - 1s 850us/step\n",
      "Epoch: 3, Batch size: 24, Value: 1.2964218211939043\n",
      "Epoch 1/3\n",
      "797/797 [==============================] - 5s 3ms/step - loss: 10.7190 - val_loss: 6.5655\n",
      "Epoch 2/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 13.0656 - val_loss: 4.7987\n",
      "Epoch 3/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 7.5278 - val_loss: 3.8461\n",
      "114/114 [==============================] - 1s 752us/step\n",
      "Epoch 1/3\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 13.3126 - val_loss: 2.9706\n",
      "Epoch 2/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 7.9517 - val_loss: 1.8185\n",
      "Epoch 3/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 10.4155 - val_loss: 1.7877\n",
      "114/114 [==============================] - 1s 1ms/step\n",
      "Epoch 1/3\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 9.8183 - val_loss: 5.9205\n",
      "Epoch 2/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 14.4744 - val_loss: 7.3860\n",
      "Epoch 3/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 6.6783 - val_loss: 1.7705\n",
      "114/114 [==============================] - 0s 920us/step\n",
      "Epoch 1/3\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 11.1388 - val_loss: 5.5549\n",
      "Epoch 2/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 14.7914 - val_loss: 3.2612\n",
      "Epoch 3/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 9.0442 - val_loss: 2.8347\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch 1/3\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 26.8617 - val_loss: 2.3938\n",
      "Epoch 2/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 14.9500 - val_loss: 4.3504\n",
      "Epoch 3/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 8.9492 - val_loss: 2.0439\n",
      "114/114 [==============================] - 1s 708us/step\n",
      "Epoch 1/3\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 8.8899 - val_loss: 8.1808\n",
      "Epoch 2/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 8.9899 - val_loss: 3.2561\n",
      "Epoch 3/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 7.2510 - val_loss: 2.8852\n",
      "114/114 [==============================] - 1s 823us/step\n",
      "Epoch 1/3\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 24.5123 - val_loss: 8.2833\n",
      "Epoch 2/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 13.2560 - val_loss: 2.0285\n",
      "Epoch 3/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 6.8928 - val_loss: 1.3776\n",
      "114/114 [==============================] - 1s 761us/step\n",
      "Epoch 1/3\n",
      "797/797 [==============================] - 5s 3ms/step - loss: 24.0439 - val_loss: 3.0778\n",
      "Epoch 2/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 11.8756 - val_loss: 2.1219\n",
      "Epoch 3/3\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 7.3116 - val_loss: 5.1434\n",
      "114/114 [==============================] - 1s 699us/step\n",
      "Epoch: 3, Batch size: 32, Value: 0.9297291381554641\n",
      "Epoch 1/3\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 13.3370 - val_loss: 8.8665\n",
      "Epoch 2/3\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 15.3495 - val_loss: 6.3086\n",
      "Epoch 3/3\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 10.5960 - val_loss: 3.1410\n",
      "114/114 [==============================] - 1s 761us/step\n",
      "Epoch 1/3\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 18.2959 - val_loss: 6.9841\n",
      "Epoch 2/3\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 14.4527 - val_loss: 1.6054\n",
      "Epoch 3/3\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 8.6941 - val_loss: 2.0798\n",
      "114/114 [==============================] - 1s 982us/step\n",
      "Epoch 1/3\n",
      "554/554 [==============================] - 4s 4ms/step - loss: 11.6005 - val_loss: 5.3762\n",
      "Epoch 2/3\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 14.5846 - val_loss: 3.8179\n",
      "Epoch 3/3\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 10.4448 - val_loss: 3.8374\n",
      "114/114 [==============================] - 1s 823us/step\n",
      "Epoch: 3, Batch size: 46, Value: 3.0260186592995764\n",
      "Epoch 1/3\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 8.9933 - val_loss: 3.9336\n",
      "Epoch 2/3\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 12.0270 - val_loss: 1.9211\n",
      "Epoch 3/3\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 13.9938 - val_loss: 2.2617\n",
      "114/114 [==============================] - 1s 973us/step\n",
      "Epoch 1/3\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 37.1057 - val_loss: 3.0708\n",
      "Epoch 2/3\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 14.6319 - val_loss: 3.0822\n",
      "Epoch 3/3\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 12.5027 - val_loss: 1.3132\n",
      "114/114 [==============================] - 1s 858us/step\n",
      "Epoch 1/3\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 15.3166 - val_loss: 3.8651\n",
      "Epoch 2/3\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 11.9706 - val_loss: 3.4033\n",
      "Epoch 3/3\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 9.1496 - val_loss: 2.3479\n",
      "114/114 [==============================] - 1s 752us/step\n",
      "Epoch 1/3\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 12.3763 - val_loss: 8.3164\n",
      "Epoch 2/3\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 13.2371 - val_loss: 3.0530\n",
      "Epoch 3/3\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 17.8470 - val_loss: 5.0149\n",
      "114/114 [==============================] - 1s 850us/step\n",
      "Epoch 1/3\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 23.4111 - val_loss: 5.4180\n",
      "Epoch 2/3\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 16.7573 - val_loss: 9.9485\n",
      "Epoch 3/3\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 10.2905 - val_loss: 2.9389\n",
      "114/114 [==============================] - 1s 858us/step\n",
      "Epoch: 3, Batch size: 64, Value: 1.1880002607743503\n",
      "Epoch 1/3\n",
      "266/266 [==============================] - 3s 6ms/step - loss: 36.1525 - val_loss: 6.6614\n",
      "Epoch 2/3\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 16.9422 - val_loss: 4.1620\n",
      "Epoch 3/3\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 13.2854 - val_loss: 1.5977\n",
      "114/114 [==============================] - 1s 743us/step\n",
      "Epoch 1/3\n",
      "266/266 [==============================] - 4s 7ms/step - loss: 16.9996 - val_loss: 10.5968\n",
      "Epoch 2/3\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 20.6266 - val_loss: 11.2165\n",
      "Epoch 3/3\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 15.8970 - val_loss: 6.8393\n",
      "114/114 [==============================] - 0s 973us/step\n",
      "Epoch 1/3\n",
      "266/266 [==============================] - 4s 6ms/step - loss: 29.8586 - val_loss: 12.8176\n",
      "Epoch 2/3\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 19.7044 - val_loss: 5.3694\n",
      "Epoch 3/3\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 15.4683 - val_loss: 3.1071\n",
      "114/114 [==============================] - 1s 735us/step\n",
      "Epoch 1/3\n",
      "266/266 [==============================] - 4s 6ms/step - loss: 11.9286 - val_loss: 11.2949\n",
      "Epoch 2/3\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 19.8535 - val_loss: 15.1931\n",
      "Epoch 3/3\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 5.3663 - val_loss: 15.4973\n",
      "114/114 [==============================] - 1s 726us/step\n",
      "Epoch: 3, Batch size: 96, Value: 1.367245537104468\n",
      "Epoch 1/3\n",
      "200/200 [==============================] - 4s 7ms/step - loss: 32.2526 - val_loss: 11.2409\n",
      "Epoch 2/3\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 21.2795 - val_loss: 5.6735\n",
      "Epoch 3/3\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 11.6627 - val_loss: 4.5097\n",
      "114/114 [==============================] - 1s 832us/step\n",
      "Epoch 1/3\n",
      "200/200 [==============================] - 4s 7ms/step - loss: 23.1160 - val_loss: 17.9812\n",
      "Epoch 2/3\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 28.1517 - val_loss: 29.9231\n",
      "Epoch 3/3\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 23.8119 - val_loss: 6.6006\n",
      "114/114 [==============================] - 1s 743us/step\n",
      "Epoch 1/3\n",
      "200/200 [==============================] - 4s 7ms/step - loss: 34.4373 - val_loss: 31.2289\n",
      "Epoch 2/3\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 20.2447 - val_loss: 27.7731\n",
      "Epoch 3/3\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 21.1935 - val_loss: 16.4713\n",
      "114/114 [==============================] - 1s 717us/step\n",
      "Epoch: 3, Batch size: 128, Value: 3.3431835529597116\n",
      "Epoch 1/3\n",
      "100/100 [==============================] - 3s 3ms/step - loss: 17.5284 - val_loss: 15.9134\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.7606 - val_loss: 4.8519\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.2742 - val_loss: 19.8684\n",
      "114/114 [==============================] - 1s 823us/step\n",
      "Epoch 1/3\n",
      "100/100 [==============================] - 4s 13ms/step - loss: 60.9840 - val_loss: 12.0804\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.8541 - val_loss: 24.4238\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 65.2094 - val_loss: 25.7837\n",
      "114/114 [==============================] - 1s 841us/step\n",
      "Epoch 1/3\n",
      "100/100 [==============================] - 4s 14ms/step - loss: 43.0919 - val_loss: 10.7199\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4136 - val_loss: 3.4130\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 8.0308 - val_loss: 3.3740\n",
      "114/114 [==============================] - 1s 735us/step\n",
      "Epoch: 3, Batch size: 256, Value: 3.7061793223554096\n",
      "Epoch 1/4\n",
      "6369/6369 [==============================] - 10s 1ms/step - loss: 7.4242 - val_loss: 19.5731\n",
      "Epoch 2/4\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.9837 - val_loss: 10.7320\n",
      "Epoch 3/4\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.0936 - val_loss: 6.0813\n",
      "Epoch 4/4\n",
      "6369/6369 [==============================] - 8s 1ms/step - loss: 3.0345 - val_loss: 5.1815\n",
      "114/114 [==============================] - 1s 761us/step\n",
      "Epoch 1/4\n",
      "6369/6369 [==============================] - 11s 1ms/step - loss: 6.6711 - val_loss: 20.5702\n",
      "Epoch 2/4\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.7547 - val_loss: 10.6262\n",
      "Epoch 3/4\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.0702 - val_loss: 7.3991\n",
      "Epoch 4/4\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.8608 - val_loss: 4.6535\n",
      "114/114 [==============================] - 0s 699us/step\n",
      "Epoch 1/4\n",
      "6369/6369 [==============================] - 11s 1ms/step - loss: 6.0724 - val_loss: 18.8675\n",
      "Epoch 2/4\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.4979 - val_loss: 8.3291\n",
      "Epoch 3/4\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.3534 - val_loss: 3.7749\n",
      "Epoch 4/4\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.4993 - val_loss: 4.6309\n",
      "114/114 [==============================] - 1s 858us/step\n",
      "Epoch: 4, Batch size: 4, Value: 8.07503398644794\n",
      "Epoch 1/4\n",
      "4246/4246 [==============================] - 8s 1ms/step - loss: 7.3159 - val_loss: 14.1591\n",
      "Epoch 2/4\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 4.1225 - val_loss: 4.7902\n",
      "Epoch 3/4\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.0948 - val_loss: 4.8473\n",
      "Epoch 4/4\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.8668 - val_loss: 3.6314\n",
      "114/114 [==============================] - 1s 708us/step\n",
      "Epoch 1/4\n",
      "4246/4246 [==============================] - 7s 1ms/step - loss: 9.4416 - val_loss: 17.4350\n",
      "Epoch 2/4\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 4.8417 - val_loss: 6.2791\n",
      "Epoch 3/4\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.0807 - val_loss: 4.0634\n",
      "Epoch 4/4\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.9147 - val_loss: 4.5815\n",
      "114/114 [==============================] - 1s 720us/step\n",
      "Epoch 1/4\n",
      "4246/4246 [==============================] - 9s 1ms/step - loss: 7.9760 - val_loss: 20.9045\n",
      "Epoch 2/4\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 6.1263 - val_loss: 9.5439\n",
      "Epoch 3/4\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.6922 - val_loss: 6.6011\n",
      "Epoch 4/4\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.9669 - val_loss: 6.0995\n",
      "114/114 [==============================] - 1s 761us/step\n",
      "Epoch: 4, Batch size: 6, Value: 6.337522015459165\n",
      "Epoch 1/4\n",
      "3185/3185 [==============================] - 7s 2ms/step - loss: 8.2682 - val_loss: 20.3223\n",
      "Epoch 2/4\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 6.7747 - val_loss: 8.4015\n",
      "Epoch 3/4\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.3095 - val_loss: 4.7074\n",
      "Epoch 4/4\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.5292 - val_loss: 2.6691\n",
      "114/114 [==============================] - 1s 752us/step\n",
      "Epoch 1/4\n",
      "3185/3185 [==============================] - 7s 1ms/step - loss: 6.2500 - val_loss: 6.4136\n",
      "Epoch 2/4\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.3513 - val_loss: 5.7262\n",
      "Epoch 3/4\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.3630 - val_loss: 2.8421\n",
      "Epoch 4/4\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.7621 - val_loss: 1.2550\n",
      "114/114 [==============================] - 1s 788us/step\n",
      "Epoch 1/4\n",
      "3185/3185 [==============================] - 7s 2ms/step - loss: 7.9384 - val_loss: 24.0739\n",
      "Epoch 2/4\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 6.2733 - val_loss: 12.0813\n",
      "Epoch 3/4\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.7763 - val_loss: 9.5173\n",
      "Epoch 4/4\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.1866 - val_loss: 6.4707\n",
      "114/114 [==============================] - 1s 823us/step\n",
      "Epoch 1/4\n",
      "3185/3185 [==============================] - 6s 1ms/step - loss: 11.2728 - val_loss: 34.3123\n",
      "Epoch 2/4\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 7.7165 - val_loss: 21.6878\n",
      "Epoch 3/4\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.0601 - val_loss: 12.9707\n",
      "Epoch 4/4\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.2622 - val_loss: 6.9032\n",
      "114/114 [==============================] - 1s 921us/step\n",
      "Epoch 1/4\n",
      "3185/3185 [==============================] - 6s 1ms/step - loss: 11.9032 - val_loss: 22.9610\n",
      "Epoch 2/4\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 9.6674 - val_loss: 23.3538\n",
      "Epoch 3/4\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 5.1129 - val_loss: 18.9994\n",
      "Epoch 4/4\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.3267 - val_loss: 17.4288\n",
      "114/114 [==============================] - 1s 699us/step\n",
      "Epoch: 4, Batch size: 8, Value: 0.8618421830027996\n",
      "Epoch 1/4\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 7.9191 - val_loss: 24.3132\n",
      "Epoch 2/4\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 8.4921 - val_loss: 16.2606\n",
      "Epoch 3/4\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 5.7335 - val_loss: 12.3077\n",
      "Epoch 4/4\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 4.0836 - val_loss: 8.1782\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch 1/4\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 8.5558 - val_loss: 5.0619\n",
      "Epoch 2/4\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 9.0872 - val_loss: 10.3838\n",
      "Epoch 3/4\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 5.1555 - val_loss: 4.9266\n",
      "Epoch 4/4\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 4.0495 - val_loss: 1.5707\n",
      "114/114 [==============================] - 1s 876us/step\n",
      "Epoch 1/4\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 6.0100 - val_loss: 2.4822\n",
      "Epoch 2/4\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 6.7388 - val_loss: 6.1937\n",
      "Epoch 3/4\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 4.9042 - val_loss: 4.7532\n",
      "Epoch 4/4\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 4.3646 - val_loss: 2.4515\n",
      "114/114 [==============================] - 1s 752us/step\n",
      "Epoch 1/4\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 9.2873 - val_loss: 1.5501\n",
      "Epoch 2/4\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 6.9730 - val_loss: 5.5409\n",
      "Epoch 3/4\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 5.6329 - val_loss: 6.9647\n",
      "Epoch 4/4\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 4.0766 - val_loss: 7.2175\n",
      "114/114 [==============================] - 1s 708us/step\n",
      "Epoch: 4, Batch size: 12, Value: 1.7964554563930666\n",
      "Epoch 1/4\n",
      "1593/1593 [==============================] - 6s 2ms/step - loss: 7.2652 - val_loss: 8.7204\n",
      "Epoch 2/4\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 5.4522 - val_loss: 7.7617\n",
      "Epoch 3/4\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 5.2668 - val_loss: 7.4879\n",
      "Epoch 4/4\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 3.9570 - val_loss: 3.8935\n",
      "114/114 [==============================] - 1s 761us/step\n",
      "Epoch 1/4\n",
      "1593/1593 [==============================] - 5s 2ms/step - loss: 11.0803 - val_loss: 13.0806\n",
      "Epoch 2/4\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 13.2364 - val_loss: 8.8480\n",
      "Epoch 3/4\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 6.7568 - val_loss: 7.7541\n",
      "Epoch 4/4\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.9352 - val_loss: 4.4880\n",
      "114/114 [==============================] - 1s 797us/step\n",
      "Epoch 1/4\n",
      "1593/1593 [==============================] - 5s 2ms/step - loss: 8.0017 - val_loss: 15.4823\n",
      "Epoch 2/4\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 5.8803 - val_loss: 12.5347\n",
      "Epoch 3/4\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 5.3724 - val_loss: 11.4769\n",
      "Epoch 4/4\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.2637 - val_loss: 9.6484\n",
      "114/114 [==============================] - 1s 752us/step\n",
      "Epoch: 4, Batch size: 16, Value: 4.8582961901421955\n",
      "Epoch 1/4\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 8.6101 - val_loss: 2.9924\n",
      "Epoch 2/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.6684 - val_loss: 2.4878\n",
      "Epoch 3/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.6587 - val_loss: 1.4046\n",
      "Epoch 4/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.2888 - val_loss: 3.3017\n",
      "114/114 [==============================] - 1s 735us/step\n",
      "Epoch 1/4\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 8.3766 - val_loss: 6.7682\n",
      "Epoch 2/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 8.2906 - val_loss: 5.9765\n",
      "Epoch 3/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 8.0087 - val_loss: 1.5145\n",
      "Epoch 4/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.1782 - val_loss: 1.2780\n",
      "114/114 [==============================] - 1s 991us/step\n",
      "Epoch 1/4\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 9.8804 - val_loss: 7.3404\n",
      "Epoch 2/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 6.8350 - val_loss: 4.5916\n",
      "Epoch 3/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.7118 - val_loss: 2.5458\n",
      "Epoch 4/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.4962 - val_loss: 2.3829\n",
      "114/114 [==============================] - 1s 735us/step\n",
      "Epoch 1/4\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 10.2187 - val_loss: 5.5500\n",
      "Epoch 2/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 9.6339 - val_loss: 1.5295\n",
      "Epoch 3/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.7497 - val_loss: 2.2952\n",
      "Epoch 4/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.5041 - val_loss: 1.4418\n",
      "114/114 [==============================] - 1s 796us/step\n",
      "Epoch 1/4\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 14.4889 - val_loss: 3.3627\n",
      "Epoch 2/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.5224 - val_loss: 1.6449\n",
      "Epoch 3/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.2313 - val_loss: 1.2494\n",
      "Epoch 4/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 6.5893 - val_loss: 1.3201\n",
      "114/114 [==============================] - 1s 752us/step\n",
      "Epoch 1/4\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 16.3667 - val_loss: 9.8137\n",
      "Epoch 2/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 11.1093 - val_loss: 7.6355\n",
      "Epoch 3/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.8682 - val_loss: 6.0772\n",
      "Epoch 4/4\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 8.0506 - val_loss: 7.2009\n",
      "114/114 [==============================] - 1s 982us/step\n",
      "Epoch: 4, Batch size: 24, Value: 0.9772657304935736\n",
      "Epoch 1/4\n",
      "797/797 [==============================] - 5s 3ms/step - loss: 14.5738 - val_loss: 1.8164\n",
      "Epoch 2/4\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 13.7142 - val_loss: 2.2834\n",
      "Epoch 3/4\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 9.8186 - val_loss: 5.1196\n",
      "Epoch 4/4\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 7.8211 - val_loss: 4.0989\n",
      "114/114 [==============================] - 1s 743us/step\n",
      "Epoch 1/4\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 10.4503 - val_loss: 6.9541\n",
      "Epoch 2/4\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 8.4917 - val_loss: 2.0644\n",
      "Epoch 3/4\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 6.1093 - val_loss: 1.4455\n",
      "Epoch 4/4\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 7.2347 - val_loss: 2.9040\n",
      "114/114 [==============================] - 1s 761us/step\n",
      "Epoch 1/4\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 11.0982 - val_loss: 2.3758\n",
      "Epoch 2/4\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 7.2230 - val_loss: 3.9702\n",
      "Epoch 3/4\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 5.6340 - val_loss: 6.6444\n",
      "Epoch 4/4\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 6.5379 - val_loss: 2.7133\n",
      "114/114 [==============================] - 1s 885us/step\n",
      "Epoch: 4, Batch size: 32, Value: 3.4312214474695937\n",
      "Epoch 1/4\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 14.1829 - val_loss: 12.3279\n",
      "Epoch 2/4\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 14.4685 - val_loss: 1.8699\n",
      "Epoch 3/4\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.8380 - val_loss: 2.2833\n",
      "Epoch 4/4\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 6.0609 - val_loss: 3.0288\n",
      "114/114 [==============================] - 1s 734us/step\n",
      "Epoch 1/4\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 8.1212 - val_loss: 2.8835\n",
      "Epoch 2/4\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 11.2410 - val_loss: 1.4353\n",
      "Epoch 3/4\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 9.2572 - val_loss: 2.4833\n",
      "Epoch 4/4\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 11.6520 - val_loss: 5.0064\n",
      "114/114 [==============================] - 1s 805us/step\n",
      "Epoch 1/4\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 13.2975 - val_loss: 6.8920\n",
      "Epoch 2/4\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 23.6914 - val_loss: 2.0068\n",
      "Epoch 3/4\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 13.7475 - val_loss: 1.7602\n",
      "Epoch 4/4\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 6.6033 - val_loss: 2.6395\n",
      "114/114 [==============================] - 1s 867us/step\n",
      "Epoch: 4, Batch size: 46, Value: 3.775166652256497\n",
      "Epoch 1/4\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 15.6522 - val_loss: 4.1123\n",
      "Epoch 2/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 14.4584 - val_loss: 2.6237\n",
      "Epoch 3/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 12.0168 - val_loss: 1.7636\n",
      "Epoch 4/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 10.2447 - val_loss: 2.1462\n",
      "114/114 [==============================] - 1s 761us/step\n",
      "Epoch 1/4\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 12.7646 - val_loss: 5.6049\n",
      "Epoch 2/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 16.2729 - val_loss: 2.7805\n",
      "Epoch 3/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 11.1729 - val_loss: 1.7709\n",
      "Epoch 4/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 7.9278 - val_loss: 2.0947\n",
      "114/114 [==============================] - 1s 832us/step\n",
      "Epoch 1/4\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 16.9282 - val_loss: 3.1444\n",
      "Epoch 2/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 11.3486 - val_loss: 5.3385\n",
      "Epoch 3/4\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 8.2913 - val_loss: 4.5576\n",
      "Epoch 4/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 5.6842 - val_loss: 1.7955\n",
      "114/114 [==============================] - 1s 779us/step\n",
      "Epoch 1/4\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 17.9497 - val_loss: 1.7720\n",
      "Epoch 2/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 11.7956 - val_loss: 2.3588\n",
      "Epoch 3/4\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 6.1104 - val_loss: 3.9922\n",
      "Epoch 4/4\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 6.3114 - val_loss: 2.0577\n",
      "114/114 [==============================] - 1s 841us/step\n",
      "Epoch 1/4\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 9.3212 - val_loss: 3.1477\n",
      "Epoch 2/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 19.3339 - val_loss: 6.2594\n",
      "Epoch 3/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 8.3708 - val_loss: 2.4483\n",
      "Epoch 4/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 8.6075 - val_loss: 2.1363\n",
      "114/114 [==============================] - 1s 973us/step\n",
      "Epoch 1/4\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 17.2695 - val_loss: 29.6693\n",
      "Epoch 2/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 8.6080 - val_loss: 2.7424\n",
      "Epoch 3/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 9.4682 - val_loss: 1.6844\n",
      "Epoch 4/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 9.5216 - val_loss: 1.2899\n",
      "114/114 [==============================] - 1s 867us/step\n",
      "Epoch 1/4\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 28.5275 - val_loss: 12.0242\n",
      "Epoch 2/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 15.1306 - val_loss: 9.6729\n",
      "Epoch 3/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 9.3996 - val_loss: 9.1074\n",
      "Epoch 4/4\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 6.9437 - val_loss: 7.9013\n",
      "114/114 [==============================] - 1s 1000us/step\n",
      "Epoch: 4, Batch size: 64, Value: 1.0929214340839064\n",
      "Epoch 1/4\n",
      "266/266 [==============================] - 4s 6ms/step - loss: 19.0484 - val_loss: 5.7308\n",
      "Epoch 2/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 8.9564 - val_loss: 1.9455\n",
      "Epoch 3/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 8.7342 - val_loss: 8.6137\n",
      "Epoch 4/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 13.6688 - val_loss: 3.8620\n",
      "114/114 [==============================] - 1s 796us/step\n",
      "Epoch 1/4\n",
      "266/266 [==============================] - 4s 6ms/step - loss: 15.1872 - val_loss: 5.4999\n",
      "Epoch 2/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 24.6798 - val_loss: 3.1558\n",
      "Epoch 3/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 10.5579 - val_loss: 1.5907\n",
      "Epoch 4/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 8.6324 - val_loss: 5.0288\n",
      "114/114 [==============================] - 0s 805us/step\n",
      "Epoch 1/4\n",
      "266/266 [==============================] - 4s 6ms/step - loss: 33.4405 - val_loss: 17.2138\n",
      "Epoch 2/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 14.0116 - val_loss: 2.9805\n",
      "Epoch 3/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 11.4077 - val_loss: 3.0317\n",
      "Epoch 4/4\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 6.5180 - val_loss: 1.8243\n",
      "114/114 [==============================] - 1s 911us/step\n",
      "Epoch 1/4\n",
      "266/266 [==============================] - 4s 6ms/step - loss: 27.8332 - val_loss: 18.5348\n",
      "Epoch 2/4\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 21.0912 - val_loss: 3.9337\n",
      "Epoch 3/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 16.0601 - val_loss: 2.1511\n",
      "Epoch 4/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 14.2789 - val_loss: 1.8270\n",
      "114/114 [==============================] - 1s 814us/step\n",
      "Epoch 1/4\n",
      "266/266 [==============================] - 4s 6ms/step - loss: 20.9725 - val_loss: 1.5060\n",
      "Epoch 2/4\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 26.7185 - val_loss: 5.7574\n",
      "Epoch 3/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 14.8051 - val_loss: 4.7918\n",
      "Epoch 4/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 9.8965 - val_loss: 2.6986\n",
      "114/114 [==============================] - 1s 779us/step\n",
      "Epoch 1/4\n",
      "266/266 [==============================] - 4s 5ms/step - loss: 10.0442 - val_loss: 5.9315\n",
      "Epoch 2/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 11.3989 - val_loss: 5.6783\n",
      "Epoch 3/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 13.1010 - val_loss: 2.9463\n",
      "Epoch 4/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 9.1658 - val_loss: 3.4480\n",
      "114/114 [==============================] - 1s 681us/step\n",
      "Epoch 1/4\n",
      "266/266 [==============================] - 4s 6ms/step - loss: 14.0263 - val_loss: 24.6819\n",
      "Epoch 2/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 13.1045 - val_loss: 20.2495\n",
      "Epoch 3/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 6.1815 - val_loss: 8.7916\n",
      "Epoch 4/4\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 6.0207 - val_loss: 6.5210\n",
      "114/114 [==============================] - 1s 779us/step\n",
      "Epoch: 4, Batch size: 96, Value: 2.4789767152667186\n",
      "Epoch 1/4\n",
      "200/200 [==============================] - 4s 9ms/step - loss: 10.9200 - val_loss: 9.2552\n",
      "Epoch 2/4\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 14.7289 - val_loss: 7.3407\n",
      "Epoch 3/4\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 10.9903 - val_loss: 1.5970\n",
      "Epoch 4/4\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 6.6818 - val_loss: 3.6145\n",
      "114/114 [==============================] - 1s 805us/step\n",
      "Epoch 1/4\n",
      "200/200 [==============================] - 4s 7ms/step - loss: 14.8171 - val_loss: 9.4167\n",
      "Epoch 2/4\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 25.5551 - val_loss: 6.9724\n",
      "Epoch 3/4\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 11.2800 - val_loss: 13.7198\n",
      "Epoch 4/4\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 9.4753 - val_loss: 14.6744\n",
      "114/114 [==============================] - 1s 699us/step\n",
      "Epoch 1/4\n",
      "200/200 [==============================] - 4s 7ms/step - loss: 44.7821 - val_loss: 2.7837\n",
      "Epoch 2/4\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 10.9032 - val_loss: 3.0562\n",
      "Epoch 3/4\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 10.9576 - val_loss: 6.6662\n",
      "Epoch 4/4\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.0754 - val_loss: 8.1392\n",
      "114/114 [==============================] - 1s 743us/step\n",
      "Epoch 1/4\n",
      "200/200 [==============================] - 4s 7ms/step - loss: 57.4507 - val_loss: 22.2420\n",
      "Epoch 2/4\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 27.0303 - val_loss: 10.8241\n",
      "Epoch 3/4\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 11.6647 - val_loss: 5.9180\n",
      "Epoch 4/4\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 8.2031 - val_loss: 16.8559\n",
      "114/114 [==============================] - 1s 991us/step\n",
      "Epoch: 4, Batch size: 128, Value: 2.786742663283187\n",
      "Epoch 1/4\n",
      "100/100 [==============================] - 3s 4ms/step - loss: 25.2252 - val_loss: 25.4224\n",
      "Epoch 2/4\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 29.7491 - val_loss: 25.3757\n",
      "Epoch 3/4\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.5567 - val_loss: 27.5489\n",
      "Epoch 4/4\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 65.4691 - val_loss: 3.2145\n",
      "114/114 [==============================] - 1s 726us/step\n",
      "Epoch 1/4\n",
      "100/100 [==============================] - 4s 13ms/step - loss: 27.6322 - val_loss: 12.3318\n",
      "Epoch 2/4\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 52.2792 - val_loss: 33.8323\n",
      "Epoch 3/4\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 85.2149 - val_loss: 8.3131\n",
      "Epoch 4/4\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.4380 - val_loss: 5.6582\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch 1/4\n",
      "100/100 [==============================] - 4s 13ms/step - loss: 25.2933 - val_loss: 2.2534\n",
      "Epoch 2/4\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.6402 - val_loss: 6.0952\n",
      "Epoch 3/4\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.4296 - val_loss: 12.1532\n",
      "Epoch 4/4\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.6511 - val_loss: 2.2193\n",
      "114/114 [==============================] - 1s 708us/step\n",
      "Epoch 1/4\n",
      "100/100 [==============================] - 4s 13ms/step - loss: 44.6661 - val_loss: 2.4371\n",
      "Epoch 2/4\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.8728 - val_loss: 8.2420\n",
      "Epoch 3/4\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.2075 - val_loss: 7.7315\n",
      "Epoch 4/4\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.2831 - val_loss: 20.7373\n",
      "114/114 [==============================] - 1s 735us/step\n",
      "Epoch 1/4\n",
      "100/100 [==============================] - 4s 13ms/step - loss: 62.2460 - val_loss: 4.7094\n",
      "Epoch 2/4\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.4150 - val_loss: 2.1019\n",
      "Epoch 3/4\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.2049 - val_loss: 7.1331\n",
      "Epoch 4/4\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.4485 - val_loss: 10.9200\n",
      "114/114 [==============================] - 1s 796us/step\n",
      "Epoch: 4, Batch size: 256, Value: 1.232081630824931\n",
      "Epoch 1/5\n",
      "6369/6369 [==============================] - 11s 1ms/step - loss: 6.8080 - val_loss: 11.4846\n",
      "Epoch 2/5\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.5457 - val_loss: 8.3938\n",
      "Epoch 3/5\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.2900 - val_loss: 9.7236\n",
      "Epoch 4/5\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.0301 - val_loss: 7.3447\n",
      "Epoch 5/5\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.7444 - val_loss: 6.3107\n",
      "114/114 [==============================] - 1s 717us/step\n",
      "Epoch 1/5\n",
      "6369/6369 [==============================] - 11s 1ms/step - loss: 8.1977 - val_loss: 23.6640\n",
      "Epoch 2/5\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.5322 - val_loss: 12.5276\n",
      "Epoch 3/5\n",
      "6369/6369 [==============================] - 8s 1ms/step - loss: 2.8044 - val_loss: 9.3080\n",
      "Epoch 4/5\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.4893 - val_loss: 7.3046\n",
      "Epoch 5/5\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.2984 - val_loss: 7.3768\n",
      "114/114 [==============================] - 1s 690us/step\n",
      "Epoch 1/5\n",
      "6369/6369 [==============================] - 11s 1ms/step - loss: 6.5194 - val_loss: 12.2198\n",
      "Epoch 2/5\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.1069 - val_loss: 8.5091\n",
      "Epoch 3/5\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.6644 - val_loss: 7.7579\n",
      "Epoch 4/5\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.4394 - val_loss: 7.7114\n",
      "Epoch 5/5\n",
      "6369/6369 [==============================] - 8s 1ms/step - loss: 2.3297 - val_loss: 7.3876\n",
      "114/114 [==============================] - 1s 858us/step\n",
      "Epoch: 5, Batch size: 4, Value: 10.631565619766096\n",
      "Epoch 1/5\n",
      "4246/4246 [==============================] - 7s 1ms/step - loss: 7.0077 - val_loss: 12.8282\n",
      "Epoch 2/5\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 4.1623 - val_loss: 8.0056\n",
      "Epoch 3/5\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.4337 - val_loss: 4.8738\n",
      "Epoch 4/5\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.1616 - val_loss: 3.2985\n",
      "Epoch 5/5\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.7296 - val_loss: 3.6420\n",
      "114/114 [==============================] - 1s 850us/step\n",
      "Epoch 1/5\n",
      "4246/4246 [==============================] - 8s 1ms/step - loss: 7.6857 - val_loss: 22.2865\n",
      "Epoch 2/5\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 5.1648 - val_loss: 11.9958\n",
      "Epoch 3/5\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.4515 - val_loss: 5.3258\n",
      "Epoch 4/5\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.2386 - val_loss: 4.1960\n",
      "Epoch 5/5\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.7715 - val_loss: 2.7374\n",
      "114/114 [==============================] - 1s 929us/step\n",
      "Epoch 1/5\n",
      "4246/4246 [==============================] - 8s 1ms/step - loss: 8.2341 - val_loss: 25.2318\n",
      "Epoch 2/5\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 6.2324 - val_loss: 16.3544\n",
      "Epoch 3/5\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.8219 - val_loss: 9.8396\n",
      "Epoch 4/5\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.7521 - val_loss: 4.2428\n",
      "Epoch 5/5\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.8264 - val_loss: 4.1011\n",
      "114/114 [==============================] - 1s 699us/step\n",
      "Epoch: 5, Batch size: 6, Value: 4.117942077870163\n",
      "Epoch 1/5\n",
      "3185/3185 [==============================] - 7s 2ms/step - loss: 11.6693 - val_loss: 24.5974\n",
      "Epoch 2/5\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 7.9068 - val_loss: 20.8723\n",
      "Epoch 3/5\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 4.8197 - val_loss: 13.7126\n",
      "Epoch 4/5\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.2102 - val_loss: 5.1698\n",
      "Epoch 5/5\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.7078 - val_loss: 3.2165\n",
      "114/114 [==============================] - 0s 788us/step\n",
      "Epoch 1/5\n",
      "3185/3185 [==============================] - 7s 1ms/step - loss: 10.5383 - val_loss: 15.5397\n",
      "Epoch 2/5\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 7.3854 - val_loss: 14.0512\n",
      "Epoch 3/5\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.6302 - val_loss: 5.0510\n",
      "Epoch 4/5\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.5875 - val_loss: 3.2209\n",
      "Epoch 5/5\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 3.0795 - val_loss: 8.9731\n",
      "114/114 [==============================] - 1s 699us/step\n",
      "Epoch 1/5\n",
      "3185/3185 [==============================] - 7s 2ms/step - loss: 10.5552 - val_loss: 30.8363\n",
      "Epoch 2/5\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 6.0634 - val_loss: 18.4994\n",
      "Epoch 3/5\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.0978 - val_loss: 11.8906\n",
      "Epoch 4/5\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 3.3856 - val_loss: 3.2078\n",
      "Epoch 5/5\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.0721 - val_loss: 2.0522\n",
      "114/114 [==============================] - 1s 894us/step\n",
      "Epoch 1/5\n",
      "3185/3185 [==============================] - 7s 2ms/step - loss: 8.6338 - val_loss: 27.5033\n",
      "Epoch 2/5\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 6.0527 - val_loss: 13.4727\n",
      "Epoch 3/5\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.6640 - val_loss: 5.2338\n",
      "Epoch 4/5\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.1370 - val_loss: 4.4900\n",
      "Epoch 5/5\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.8427 - val_loss: 3.6161\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch: 5, Batch size: 8, Value: 2.7683369933995694\n",
      "Epoch 1/5\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 10.0007 - val_loss: 16.5129\n",
      "Epoch 2/5\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 8.6585 - val_loss: 15.2768\n",
      "Epoch 3/5\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 6.2080 - val_loss: 8.5248\n",
      "Epoch 4/5\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 4.1950 - val_loss: 8.6829\n",
      "Epoch 5/5\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.6481 - val_loss: 7.6244\n",
      "114/114 [==============================] - 1s 743us/step\n",
      "Epoch 1/5\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 7.5158 - val_loss: 14.1766\n",
      "Epoch 2/5\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 5.6519 - val_loss: 8.2936\n",
      "Epoch 3/5\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.7426 - val_loss: 5.9280\n",
      "Epoch 4/5\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.1092 - val_loss: 1.3058\n",
      "Epoch 5/5\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.2539 - val_loss: 1.4225\n",
      "114/114 [==============================] - 1s 805us/step\n",
      "Epoch 1/5\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 7.3252 - val_loss: 18.4762\n",
      "Epoch 2/5\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 4.4210 - val_loss: 11.4087\n",
      "Epoch 3/5\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.3390 - val_loss: 7.3795\n",
      "Epoch 4/5\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 2.9650 - val_loss: 5.1304\n",
      "Epoch 5/5\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 2.8395 - val_loss: 6.5507\n",
      "114/114 [==============================] - 1s 717us/step\n",
      "Epoch 1/5\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 13.6057 - val_loss: 26.7670\n",
      "Epoch 2/5\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 13.9788 - val_loss: 15.8386\n",
      "Epoch 3/5\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 6.6669 - val_loss: 11.9501\n",
      "Epoch 4/5\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 4.3247 - val_loss: 10.8872\n",
      "Epoch 5/5\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 3.6992 - val_loss: 8.2169\n",
      "114/114 [==============================] - 1s 779us/step\n",
      "Epoch: 5, Batch size: 12, Value: 1.5819494480278786\n",
      "Epoch 1/5\n",
      "1593/1593 [==============================] - 5s 2ms/step - loss: 8.6142 - val_loss: 19.4612\n",
      "Epoch 2/5\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 7.2948 - val_loss: 9.9128\n",
      "Epoch 3/5\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 5.0644 - val_loss: 7.6838\n",
      "Epoch 4/5\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.3599 - val_loss: 5.3621\n",
      "Epoch 5/5\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 3.8348 - val_loss: 4.9374\n",
      "114/114 [==============================] - 1s 743us/step\n",
      "Epoch 1/5\n",
      "1593/1593 [==============================] - 4s 2ms/step - loss: 11.0231 - val_loss: 14.4657\n",
      "Epoch 2/5\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 6.3885 - val_loss: 9.1058\n",
      "Epoch 3/5\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.7602 - val_loss: 6.9723\n",
      "Epoch 4/5\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.5742 - val_loss: 1.1083\n",
      "Epoch 5/5\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.3475 - val_loss: 3.3856\n",
      "114/114 [==============================] - 1s 814us/step\n",
      "Epoch 1/5\n",
      "1593/1593 [==============================] - 5s 2ms/step - loss: 10.2396 - val_loss: 11.4600\n",
      "Epoch 2/5\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 7.5268 - val_loss: 11.0345\n",
      "Epoch 3/5\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 7.3899 - val_loss: 7.9359\n",
      "Epoch 4/5\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.7350 - val_loss: 6.5444\n",
      "Epoch 5/5\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.9785 - val_loss: 7.0430\n",
      "114/114 [==============================] - 0s 779us/step\n",
      "Epoch: 5, Batch size: 16, Value: 5.469191935508328\n",
      "Epoch 1/5\n",
      "1062/1062 [==============================] - 5s 3ms/step - loss: 11.7600 - val_loss: 12.3571\n",
      "Epoch 2/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.7649 - val_loss: 9.7171\n",
      "Epoch 3/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.2486 - val_loss: 7.4323\n",
      "Epoch 4/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.6149 - val_loss: 5.5632\n",
      "Epoch 5/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 3.0440 - val_loss: 3.8182\n",
      "114/114 [==============================] - 1s 735us/step\n",
      "Epoch 1/5\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 12.4538 - val_loss: 6.4008\n",
      "Epoch 2/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 11.5755 - val_loss: 3.6261\n",
      "Epoch 3/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.6744 - val_loss: 3.4514\n",
      "Epoch 4/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 3.9660 - val_loss: 1.1823\n",
      "Epoch 5/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 3.1038 - val_loss: 2.2724\n",
      "114/114 [==============================] - 1s 726us/step\n",
      "Epoch 1/5\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 16.3507 - val_loss: 8.1301\n",
      "Epoch 2/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 10.6174 - val_loss: 4.2392\n",
      "Epoch 3/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 9.3988 - val_loss: 4.0628\n",
      "Epoch 4/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 8.1573 - val_loss: 4.2272\n",
      "Epoch 5/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 6.0774 - val_loss: 4.2840\n",
      "114/114 [==============================] - 0s 726us/step\n",
      "Epoch 1/5\n",
      "1062/1062 [==============================] - 4s 2ms/step - loss: 11.9038 - val_loss: 7.1427\n",
      "Epoch 2/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 17.4495 - val_loss: 9.2034\n",
      "Epoch 3/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 8.4779 - val_loss: 7.4591\n",
      "Epoch 4/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.0706 - val_loss: 10.2871\n",
      "Epoch 5/5\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.9197 - val_loss: 6.1134\n",
      "114/114 [==============================] - 1s 743us/step\n",
      "Epoch: 5, Batch size: 24, Value: 2.0358722181369724\n",
      "Epoch 1/5\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 13.0543 - val_loss: 3.7628\n",
      "Epoch 2/5\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 11.9391 - val_loss: 2.0692\n",
      "Epoch 3/5\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 8.3807 - val_loss: 2.3604\n",
      "Epoch 4/5\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 7.0038 - val_loss: 5.8730\n",
      "Epoch 5/5\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 6.2483 - val_loss: 4.5933\n",
      "114/114 [==============================] - 1s 726us/step\n",
      "Epoch 1/5\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 10.3624 - val_loss: 12.0457\n",
      "Epoch 2/5\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 8.3176 - val_loss: 10.2539\n",
      "Epoch 3/5\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 6.3077 - val_loss: 1.2358\n",
      "Epoch 4/5\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 4.5154 - val_loss: 1.5017\n",
      "Epoch 5/5\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 3.9002 - val_loss: 2.5782\n",
      "114/114 [==============================] - 0s 858us/step\n",
      "Epoch 1/5\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 11.5574 - val_loss: 2.6762\n",
      "Epoch 2/5\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 13.8125 - val_loss: 1.3074\n",
      "Epoch 3/5\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 6.6996 - val_loss: 2.1435\n",
      "Epoch 4/5\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 7.5745 - val_loss: 1.7317\n",
      "Epoch 5/5\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 6.9469 - val_loss: 5.2154\n",
      "114/114 [==============================] - 1s 726us/step\n",
      "Epoch: 5, Batch size: 32, Value: 3.7765679187614247\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 21.8340 - val_loss: 3.7332\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 12.2183 - val_loss: 3.8852\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 9.8133 - val_loss: 1.2767\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.1114 - val_loss: 1.1498\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 5.8760 - val_loss: 1.2572\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 6.9338 - val_loss: 2.4360\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 9.2213 - val_loss: 4.9993\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 8.9815 - val_loss: 10.9139\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 8.9659 - val_loss: 6.0615\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 6.8152 - val_loss: 4.0105\n",
      "114/114 [==============================] - 1s 717us/step\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 4s 4ms/step - loss: 6.6699 - val_loss: 5.8297\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 8.2727 - val_loss: 4.9950\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 5.0562 - val_loss: 1.6877\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.2641 - val_loss: 4.8311\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 6.8942 - val_loss: 1.7433\n",
      "114/114 [==============================] - 1s 894us/step\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 11.3584 - val_loss: 12.4239\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 16.0944 - val_loss: 1.9598\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 9.2489 - val_loss: 2.3970\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.4651 - val_loss: 2.0680\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 1s 2ms/step - loss: 6.4267 - val_loss: 3.7794\n",
      "114/114 [==============================] - 1s 752us/step\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 13.7845 - val_loss: 4.9779\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 8.8884 - val_loss: 1.8243\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 11.3583 - val_loss: 1.5521\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.4415 - val_loss: 3.7420\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 8.6819 - val_loss: 1.7564\n",
      "114/114 [==============================] - 1s 814us/step\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 10.8608 - val_loss: 4.3276\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 11.3825 - val_loss: 1.8148\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.2285 - val_loss: 3.1077\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.6915 - val_loss: 1.3645\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 6.0697 - val_loss: 1.4910\n",
      "114/114 [==============================] - 1s 832us/step\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 14.5088 - val_loss: 4.1038\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 14.4275 - val_loss: 2.1153\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 11.9822 - val_loss: 6.4301\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.8454 - val_loss: 2.1093\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.6571 - val_loss: 2.1608\n",
      "114/114 [==============================] - 1s 796us/step\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 16.6226 - val_loss: 2.5364\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 10.7158 - val_loss: 2.3079\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.8472 - val_loss: 2.1001\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 6.6876 - val_loss: 1.5379\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 8.5397 - val_loss: 1.6854\n",
      "114/114 [==============================] - 1s 788us/step\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 11.7938 - val_loss: 3.4196\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.9705 - val_loss: 2.4771\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 15.1128 - val_loss: 2.1262\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.5072 - val_loss: 1.5081\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 5.4460 - val_loss: 1.8803\n",
      "114/114 [==============================] - 1s 832us/step\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 3s 2ms/step - loss: 16.5162 - val_loss: 6.9471\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 15.9170 - val_loss: 5.0890\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 11.8555 - val_loss: 5.5581\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 10.0520 - val_loss: 1.2571\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 10.5247 - val_loss: 2.1819\n",
      "114/114 [==============================] - 1s 796us/step\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 16.8949 - val_loss: 4.6880\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 12.1962 - val_loss: 2.5765\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 11.3742 - val_loss: 3.2955\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 13.1349 - val_loss: 5.6194\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 9.5322 - val_loss: 2.1249\n",
      "114/114 [==============================] - 1s 823us/step\n",
      "Epoch 1/5\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 11.8509 - val_loss: 2.1108\n",
      "Epoch 2/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 16.1420 - val_loss: 2.2320\n",
      "Epoch 3/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 21.0012 - val_loss: 4.0740\n",
      "Epoch 4/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 12.1323 - val_loss: 1.8595\n",
      "Epoch 5/5\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 14.8524 - val_loss: 4.6612\n",
      "114/114 [==============================] - 1s 903us/step\n",
      "Epoch: 5, Batch size: 46, Value: 0.887773875427631\n",
      "Epoch 1/5\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 14.2029 - val_loss: 9.1974\n",
      "Epoch 2/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 15.7358 - val_loss: 2.7728\n",
      "Epoch 3/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 5.4336 - val_loss: 3.3212\n",
      "Epoch 4/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 5.7341 - val_loss: 2.9875\n",
      "Epoch 5/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 6.6151 - val_loss: 1.3238\n",
      "114/114 [==============================] - 1s 761us/step\n",
      "Epoch 1/5\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 16.8754 - val_loss: 3.4410\n",
      "Epoch 2/5\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 15.9290 - val_loss: 5.6090\n",
      "Epoch 3/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 9.5565 - val_loss: 3.3374\n",
      "Epoch 4/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 8.1545 - val_loss: 3.7006\n",
      "Epoch 5/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 7.2565 - val_loss: 1.4490\n",
      "114/114 [==============================] - 1s 735us/step\n",
      "Epoch 1/5\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 9.3067 - val_loss: 2.8247\n",
      "Epoch 2/5\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 13.2175 - val_loss: 3.2839\n",
      "Epoch 3/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 8.2502 - val_loss: 2.1737\n",
      "Epoch 4/5\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 9.4379 - val_loss: 3.1750\n",
      "Epoch 5/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 7.8149 - val_loss: 3.7715\n",
      "114/114 [==============================] - 1s 761us/step\n",
      "Epoch 1/5\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 14.5630 - val_loss: 24.6844\n",
      "Epoch 2/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 21.4534 - val_loss: 17.2980\n",
      "Epoch 3/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 12.9049 - val_loss: 1.7702\n",
      "Epoch 4/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 11.5027 - val_loss: 1.8332\n",
      "Epoch 5/5\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 7.0905 - val_loss: 4.4081\n",
      "114/114 [==============================] - 1s 761us/step\n",
      "Epoch 1/5\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 12.3728 - val_loss: 2.6623\n",
      "Epoch 2/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 16.1163 - val_loss: 2.1845\n",
      "Epoch 3/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 13.1846 - val_loss: 4.5963\n",
      "Epoch 4/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 12.8690 - val_loss: 4.7214\n",
      "Epoch 5/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 8.0423 - val_loss: 1.6232\n",
      "114/114 [==============================] - 1s 805us/step\n",
      "Epoch 1/5\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 8.7315 - val_loss: 11.1899\n",
      "Epoch 2/5\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 13.8217 - val_loss: 1.3497\n",
      "Epoch 3/5\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 9.2497 - val_loss: 2.6574\n",
      "Epoch 4/5\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 12.2327 - val_loss: 2.4776\n",
      "Epoch 5/5\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 7.0482 - val_loss: 2.7665\n",
      "114/114 [==============================] - 1s 690us/step\n",
      "Epoch: 5, Batch size: 64, Value: 1.0594586234596877\n",
      "Epoch 1/5\n",
      "266/266 [==============================] - 4s 6ms/step - loss: 19.3489 - val_loss: 21.7883\n",
      "Epoch 2/5\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 11.9799 - val_loss: 10.3133\n",
      "Epoch 3/5\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 13.1080 - val_loss: 6.8211\n",
      "Epoch 4/5\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 12.1702 - val_loss: 2.3288\n",
      "Epoch 5/5\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 7.5220 - val_loss: 1.7573\n",
      "114/114 [==============================] - 1s 832us/step\n",
      "Epoch 1/5\n",
      "266/266 [==============================] - 4s 6ms/step - loss: 25.8297 - val_loss: 14.4324\n",
      "Epoch 2/5\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 33.1607 - val_loss: 2.8476\n",
      "Epoch 3/5\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 16.4317 - val_loss: 2.3514\n",
      "Epoch 4/5\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 6.6824 - val_loss: 3.1976\n",
      "Epoch 5/5\n",
      "266/266 [==============================] - 1s 3ms/step - loss: 11.2014 - val_loss: 5.6375\n",
      "114/114 [==============================] - 1s 761us/step\n",
      "Epoch 1/5\n",
      "266/266 [==============================] - 4s 6ms/step - loss: 24.1069 - val_loss: 26.4323\n",
      "Epoch 2/5\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 26.8729 - val_loss: 14.9467\n",
      "Epoch 3/5\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 18.7903 - val_loss: 2.9431\n",
      "Epoch 4/5\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 7.4784 - val_loss: 6.1444\n",
      "Epoch 5/5\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 9.7390 - val_loss: 2.6198\n",
      "114/114 [==============================] - 1s 858us/step\n",
      "Epoch 1/5\n",
      "266/266 [==============================] - 4s 6ms/step - loss: 10.5200 - val_loss: 8.6802\n",
      "Epoch 2/5\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 15.9485 - val_loss: 5.2822\n",
      "Epoch 3/5\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 22.9277 - val_loss: 16.6947\n",
      "Epoch 4/5\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 5.5542 - val_loss: 2.5508\n",
      "Epoch 5/5\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 6.4962 - val_loss: 4.7911\n",
      "114/114 [==============================] - 1s 779us/step\n",
      "Epoch: 5, Batch size: 96, Value: 1.351959239906352\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 4s 7ms/step - loss: 30.9315 - val_loss: 13.9528\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 18.3456 - val_loss: 12.8211\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 11.9219 - val_loss: 3.0994\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 10.0663 - val_loss: 2.9624\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 9.3483 - val_loss: 1.9276\n",
      "114/114 [==============================] - 1s 752us/step\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 4s 7ms/step - loss: 33.2612 - val_loss: 2.9110\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 22.1802 - val_loss: 2.6803\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 14.4032 - val_loss: 8.5909\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 10.5664 - val_loss: 4.8556\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 8.0359 - val_loss: 2.6725\n",
      "114/114 [==============================] - 1s 867us/step\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 4s 8ms/step - loss: 19.0207 - val_loss: 28.7453\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 22.1944 - val_loss: 15.3905\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.2161 - val_loss: 12.2453\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 15.7707 - val_loss: 17.7873\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 13.1118 - val_loss: 14.7533\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 4s 7ms/step - loss: 15.0631 - val_loss: 22.6072\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 20.4785 - val_loss: 19.6385\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 13.3114 - val_loss: 11.6774\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 7.3884 - val_loss: 7.6076\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 6.5477 - val_loss: 3.2339\n",
      "114/114 [==============================] - 1s 841us/step\n",
      "Epoch: 5, Batch size: 128, Value: 1.181948318705706\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 3s 3ms/step - loss: 22.3484 - val_loss: 33.5266\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 55.7372 - val_loss: 48.2983\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 94.4527 - val_loss: 12.2087\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.3764 - val_loss: 11.8532\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 24.8710 - val_loss: 6.9290\n",
      "114/114 [==============================] - 1s 779us/step\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 4s 14ms/step - loss: 60.6205 - val_loss: 37.2290\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 56.4698 - val_loss: 18.1774\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 47.6776 - val_loss: 19.4471\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 68.1331 - val_loss: 14.0704\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 49.0760 - val_loss: 12.2436\n",
      "114/114 [==============================] - 1s 796us/step\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 4s 13ms/step - loss: 28.7092 - val_loss: 15.1697\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.8919 - val_loss: 25.7523\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 92.0514 - val_loss: 16.7076\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 71.7874 - val_loss: 3.1355\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 54.4676 - val_loss: 3.0839\n",
      "114/114 [==============================] - 1s 717us/step\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 4s 13ms/step - loss: 22.8722 - val_loss: 11.4230\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.0447 - val_loss: 27.0060\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.6357 - val_loss: 20.2680\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.2019 - val_loss: 3.5147\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.6412 - val_loss: 2.1910\n",
      "114/114 [==============================] - 1s 752us/step\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 4s 14ms/step - loss: 62.0323 - val_loss: 3.4614\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.4948 - val_loss: 16.4246\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.9822 - val_loss: 16.7789\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 23.1261 - val_loss: 38.7177\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 62.8822 - val_loss: 31.1930\n",
      "114/114 [==============================] - 1s 761us/step\n",
      "Epoch: 5, Batch size: 256, Value: 1.4530184090356666\n",
      "Epoch 1/6\n",
      "6369/6369 [==============================] - 11s 1ms/step - loss: 6.8313 - val_loss: 25.8879\n",
      "Epoch 2/6\n",
      "6369/6369 [==============================] - 8s 1ms/step - loss: 3.5823 - val_loss: 12.3127\n",
      "Epoch 3/6\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.2963 - val_loss: 7.1418\n",
      "Epoch 4/6\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.5330 - val_loss: 6.0939\n",
      "Epoch 5/6\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.3203 - val_loss: 5.7067\n",
      "Epoch 6/6\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.1855 - val_loss: 5.3274\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch 1/6\n",
      "6369/6369 [==============================] - 11s 1ms/step - loss: 5.9342 - val_loss: 16.2350\n",
      "Epoch 2/6\n",
      "6369/6369 [==============================] - 8s 1ms/step - loss: 3.4814 - val_loss: 9.4029\n",
      "Epoch 3/6\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.7833 - val_loss: 6.9456\n",
      "Epoch 4/6\n",
      "6369/6369 [==============================] - 8s 1ms/step - loss: 2.6033 - val_loss: 6.6239\n",
      "Epoch 5/6\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.3416 - val_loss: 5.7670\n",
      "Epoch 6/6\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.1654 - val_loss: 5.5859\n",
      "114/114 [==============================] - 1s 823us/step\n",
      "Epoch 1/6\n",
      "6369/6369 [==============================] - 11s 1ms/step - loss: 6.1253 - val_loss: 16.6973\n",
      "Epoch 2/6\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.5201 - val_loss: 9.1624\n",
      "Epoch 3/6\n",
      "6369/6369 [==============================] - 8s 1ms/step - loss: 2.9645 - val_loss: 7.4246\n",
      "Epoch 4/6\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.7714 - val_loss: 5.5602\n",
      "Epoch 5/6\n",
      "6369/6369 [==============================] - 8s 1ms/step - loss: 2.6092 - val_loss: 3.6586\n",
      "Epoch 6/6\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.4913 - val_loss: 3.5870\n",
      "114/114 [==============================] - 1s 858us/step\n",
      "Epoch: 6, Batch size: 4, Value: 5.836406708073453\n",
      "Epoch 1/6\n",
      "4246/4246 [==============================] - 9s 1ms/step - loss: 8.1870 - val_loss: 25.3875\n",
      "Epoch 2/6\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 4.6805 - val_loss: 9.9293\n",
      "Epoch 3/6\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.3412 - val_loss: 4.2934\n",
      "Epoch 4/6\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.8285 - val_loss: 2.8106\n",
      "Epoch 5/6\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.6974 - val_loss: 2.9256\n",
      "Epoch 6/6\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.4342 - val_loss: 2.2460\n",
      "114/114 [==============================] - 1s 805us/step\n",
      "Epoch 1/6\n",
      "4246/4246 [==============================] - 8s 1ms/step - loss: 6.4474 - val_loss: 19.6976\n",
      "Epoch 2/6\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 4.3478 - val_loss: 10.7452\n",
      "Epoch 3/6\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.4402 - val_loss: 6.5757\n",
      "Epoch 4/6\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.7861 - val_loss: 4.8640\n",
      "Epoch 5/6\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.4624 - val_loss: 3.6988\n",
      "Epoch 6/6\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.2895 - val_loss: 3.2166\n",
      "114/114 [==============================] - 1s 743us/step\n",
      "Epoch 1/6\n",
      "4246/4246 [==============================] - 7s 1ms/step - loss: 9.2908 - val_loss: 25.4780\n",
      "Epoch 2/6\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 4.7475 - val_loss: 17.2544\n",
      "Epoch 3/6\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.5465 - val_loss: 8.8770\n",
      "Epoch 4/6\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.0538 - val_loss: 5.2721\n",
      "Epoch 5/6\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.7660 - val_loss: 4.1179\n",
      "Epoch 6/6\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.4579 - val_loss: 3.6178\n",
      "114/114 [==============================] - 0s 938us/step\n",
      "Epoch: 6, Batch size: 6, Value: 3.0718806033752215\n",
      "Epoch 1/6\n",
      "3185/3185 [==============================] - 7s 2ms/step - loss: 7.0008 - val_loss: 16.2368\n",
      "Epoch 2/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.2808 - val_loss: 3.6594\n",
      "Epoch 3/6\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 3.1751 - val_loss: 4.5012\n",
      "Epoch 4/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.8700 - val_loss: 4.8088\n",
      "Epoch 5/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.7122 - val_loss: 4.4482\n",
      "Epoch 6/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.5736 - val_loss: 3.8817\n",
      "114/114 [==============================] - 1s 726us/step\n",
      "Epoch 1/6\n",
      "3185/3185 [==============================] - 7s 2ms/step - loss: 9.3975 - val_loss: 25.8900\n",
      "Epoch 2/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 7.0777 - val_loss: 22.6605\n",
      "Epoch 3/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.7342 - val_loss: 13.0176\n",
      "Epoch 4/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.3819 - val_loss: 3.4883\n",
      "Epoch 5/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.8119 - val_loss: 1.4336\n",
      "Epoch 6/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.6929 - val_loss: 1.7632\n",
      "114/114 [==============================] - 1s 779us/step\n",
      "Epoch 1/6\n",
      "3185/3185 [==============================] - 7s 2ms/step - loss: 9.6578 - val_loss: 22.2426\n",
      "Epoch 2/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 6.6845 - val_loss: 20.2530\n",
      "Epoch 3/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.9578 - val_loss: 16.2092\n",
      "Epoch 4/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.7768 - val_loss: 11.0525\n",
      "Epoch 5/6\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 3.0623 - val_loss: 6.2883\n",
      "Epoch 6/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.6014 - val_loss: 1.3958\n",
      "114/114 [==============================] - 1s 814us/step\n",
      "Epoch 1/6\n",
      "3185/3185 [==============================] - 8s 2ms/step - loss: 8.3872 - val_loss: 29.4872\n",
      "Epoch 2/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 7.0685 - val_loss: 21.3486\n",
      "Epoch 3/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.0402 - val_loss: 13.3267\n",
      "Epoch 4/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.3525 - val_loss: 7.9763\n",
      "Epoch 5/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.7599 - val_loss: 5.0940\n",
      "Epoch 6/6\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 2.7501 - val_loss: 4.7016\n",
      "114/114 [==============================] - 1s 823us/step\n",
      "Epoch 1/6\n",
      "3185/3185 [==============================] - 7s 1ms/step - loss: 10.5044 - val_loss: 15.0283\n",
      "Epoch 2/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.6863 - val_loss: 15.0357\n",
      "Epoch 3/6\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 3.4038 - val_loss: 5.9150\n",
      "Epoch 4/6\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 2.8020 - val_loss: 1.7590\n",
      "Epoch 5/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.4737 - val_loss: 1.4981\n",
      "Epoch 6/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.4124 - val_loss: 1.9923\n",
      "114/114 [==============================] - 1s 735us/step\n",
      "Epoch 1/6\n",
      "3185/3185 [==============================] - 7s 1ms/step - loss: 10.3356 - val_loss: 20.7428\n",
      "Epoch 2/6\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 5.9304 - val_loss: 10.4215\n",
      "Epoch 3/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.0970 - val_loss: 3.8709\n",
      "Epoch 4/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.0695 - val_loss: 2.5544\n",
      "Epoch 5/6\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 3.0058 - val_loss: 1.3925\n",
      "Epoch 6/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.6412 - val_loss: 1.4443\n",
      "114/114 [==============================] - 0s 788us/step\n",
      "Epoch 1/6\n",
      "3185/3185 [==============================] - 6s 1ms/step - loss: 7.7630 - val_loss: 19.4698\n",
      "Epoch 2/6\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 5.3623 - val_loss: 11.0157\n",
      "Epoch 3/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.8690 - val_loss: 7.9512\n",
      "Epoch 4/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.2737 - val_loss: 3.3056\n",
      "Epoch 5/6\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.7296 - val_loss: 4.0925\n",
      "Epoch 6/6\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 2.5019 - val_loss: 3.2724\n",
      "114/114 [==============================] - 1s 726us/step\n",
      "Epoch: 6, Batch size: 8, Value: 0.8339581013472538\n",
      "Epoch 1/6\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 10.4101 - val_loss: 21.3019\n",
      "Epoch 2/6\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 6.2804 - val_loss: 9.8107\n",
      "Epoch 3/6\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 4.3682 - val_loss: 9.0567\n",
      "Epoch 4/6\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.6231 - val_loss: 6.6174\n",
      "Epoch 5/6\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.2447 - val_loss: 4.7812\n",
      "Epoch 6/6\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.0725 - val_loss: 3.8213\n",
      "114/114 [==============================] - 1s 912us/step\n",
      "Epoch 1/6\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 8.9917 - val_loss: 11.5067\n",
      "Epoch 2/6\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 5.8518 - val_loss: 8.6056\n",
      "Epoch 3/6\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.1864 - val_loss: 3.9325\n",
      "Epoch 4/6\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 2.4950 - val_loss: 3.3223\n",
      "Epoch 5/6\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 2.7616 - val_loss: 2.5735\n",
      "Epoch 6/6\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 2.6817 - val_loss: 2.1974\n",
      "114/114 [==============================] - 1s 938us/step\n",
      "Epoch 1/6\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 11.8063 - val_loss: 19.2414\n",
      "Epoch 2/6\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 9.0536 - val_loss: 15.7075\n",
      "Epoch 3/6\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 4.4223 - val_loss: 10.0876\n",
      "Epoch 4/6\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.7659 - val_loss: 7.7114\n",
      "Epoch 5/6\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 4.2132 - val_loss: 4.7210\n",
      "Epoch 6/6\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 3.6964 - val_loss: 3.7212\n",
      "114/114 [==============================] - 1s 823us/step\n",
      "Epoch 1/6\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 7.7711 - val_loss: 4.4949\n",
      "Epoch 2/6\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 7.7879 - val_loss: 7.8974\n",
      "Epoch 3/6\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 4.3990 - val_loss: 6.3134\n",
      "Epoch 4/6\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 4.1525 - val_loss: 5.4610\n",
      "Epoch 5/6\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 3.5578 - val_loss: 2.9528\n",
      "Epoch 6/6\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.2456 - val_loss: 3.8306\n",
      "114/114 [==============================] - 1s 867us/step\n",
      "Epoch: 6, Batch size: 12, Value: 2.804112546456035\n",
      "Epoch 1/6\n",
      "1593/1593 [==============================] - 5s 2ms/step - loss: 14.4128 - val_loss: 21.1832\n",
      "Epoch 2/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 12.4327 - val_loss: 18.7625\n",
      "Epoch 3/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 9.7151 - val_loss: 15.9668\n",
      "Epoch 4/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 6.6848 - val_loss: 11.6318\n",
      "Epoch 5/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 5.3541 - val_loss: 8.5305\n",
      "Epoch 6/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.4388 - val_loss: 7.9937\n",
      "114/114 [==============================] - 1s 867us/step\n",
      "Epoch 1/6\n",
      "1593/1593 [==============================] - 5s 2ms/step - loss: 12.2282 - val_loss: 4.8457\n",
      "Epoch 2/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 6.7076 - val_loss: 3.9169\n",
      "Epoch 3/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.7248 - val_loss: 3.9354\n",
      "Epoch 4/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.0497 - val_loss: 5.3130\n",
      "Epoch 5/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 3.5158 - val_loss: 2.3280\n",
      "Epoch 6/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 3.5505 - val_loss: 2.0223\n",
      "114/114 [==============================] - 1s 876us/step\n",
      "Epoch 1/6\n",
      "1593/1593 [==============================] - 6s 2ms/step - loss: 7.3679 - val_loss: 17.4546\n",
      "Epoch 2/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 8.7015 - val_loss: 10.0349\n",
      "Epoch 3/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 7.6750 - val_loss: 7.4278\n",
      "Epoch 4/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 5.8331 - val_loss: 7.1917\n",
      "Epoch 5/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.0479 - val_loss: 10.8267\n",
      "Epoch 6/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.5777 - val_loss: 13.3451\n",
      "114/114 [==============================] - 1s 929us/step\n",
      "Epoch 1/6\n",
      "1593/1593 [==============================] - 6s 2ms/step - loss: 7.2524 - val_loss: 9.0804\n",
      "Epoch 2/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 7.2095 - val_loss: 7.7868\n",
      "Epoch 3/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 5.1471 - val_loss: 8.7547\n",
      "Epoch 4/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.5212 - val_loss: 7.5361\n",
      "Epoch 5/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 3.8049 - val_loss: 3.2607\n",
      "Epoch 6/6\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 3.5888 - val_loss: 5.9274\n",
      "114/114 [==============================] - 1s 814us/step\n",
      "Epoch: 6, Batch size: 16, Value: 2.991536681763545\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 9.1070 - val_loss: 4.7666\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 9.1035 - val_loss: 3.7418\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.3031 - val_loss: 4.6294\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.4439 - val_loss: 6.5874\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.3058 - val_loss: 5.3903\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 3.9994 - val_loss: 7.8658\n",
      "114/114 [==============================] - 1s 708us/step\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 10.2893 - val_loss: 10.2253\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 10.4088 - val_loss: 2.2860\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.2601 - val_loss: 3.0105\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 6.3970 - val_loss: 2.9370\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.0491 - val_loss: 6.2057\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.4521 - val_loss: 3.2116\n",
      "114/114 [==============================] - 0s 761us/step\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 10.7642 - val_loss: 6.9229\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 11.0546 - val_loss: 2.0672\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.9309 - val_loss: 1.2864\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 6.1253 - val_loss: 1.9464\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.4809 - val_loss: 2.0792\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.9652 - val_loss: 1.2025\n",
      "114/114 [==============================] - 1s 735us/step\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 4s 2ms/step - loss: 15.3806 - val_loss: 9.6647\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 11.7204 - val_loss: 11.4671\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.4892 - val_loss: 1.9068\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 11.2853 - val_loss: 1.6289\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 6.7152 - val_loss: 1.9616\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 6.5543 - val_loss: 2.8726\n",
      "114/114 [==============================] - 1s 876us/step\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 7.0728 - val_loss: 7.3121\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 10.6496 - val_loss: 4.2297\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 6.7988 - val_loss: 4.0920\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.9893 - val_loss: 2.9310\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 3.7864 - val_loss: 2.7976\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.0988 - val_loss: 1.3795\n",
      "114/114 [==============================] - 1s 796us/step\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 10.1481 - val_loss: 13.9191\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 10.6534 - val_loss: 12.1294\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 8.3848 - val_loss: 8.8463\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.4213 - val_loss: 3.6103\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.3152 - val_loss: 2.5691\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.2646 - val_loss: 2.6366\n",
      "114/114 [==============================] - 1s 867us/step\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 10.1361 - val_loss: 5.7295\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 2s 2ms/step - loss: 11.6484 - val_loss: 4.3712\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 8.5761 - val_loss: 4.3744\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 2s 2ms/step - loss: 4.8275 - val_loss: 1.8253\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.4570 - val_loss: 1.4771\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 2s 2ms/step - loss: 4.6397 - val_loss: 1.9882\n",
      "114/114 [==============================] - 1s 726us/step\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 11.6311 - val_loss: 7.5554\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 9.0055 - val_loss: 11.4616\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.6362 - val_loss: 5.3585\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.6339 - val_loss: 6.2669\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.0992 - val_loss: 2.5533\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 3.3688 - val_loss: 2.4137\n",
      "114/114 [==============================] - 1s 752us/step\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 5s 3ms/step - loss: 16.8011 - val_loss: 15.0270\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 9.5781 - val_loss: 5.9487\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 8.7284 - val_loss: 5.9262\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.8223 - val_loss: 5.7036\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.7950 - val_loss: 2.6626\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.1196 - val_loss: 2.6628\n",
      "114/114 [==============================] - 1s 735us/step\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 7.7053 - val_loss: 5.0885\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 8.0723 - val_loss: 5.2871\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 6.7622 - val_loss: 4.4287\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.9563 - val_loss: 2.4685\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.3241 - val_loss: 1.6432\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.9911 - val_loss: 2.6843\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 10.6723 - val_loss: 5.3286\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 9.0471 - val_loss: 2.5090\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.5017 - val_loss: 2.4832\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.2066 - val_loss: 1.7552\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.7449 - val_loss: 1.3704\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.0872 - val_loss: 1.6037\n",
      "114/114 [==============================] - 1s 832us/step\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 4s 2ms/step - loss: 9.5109 - val_loss: 22.5402\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 11.3817 - val_loss: 1.9114\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 6.3523 - val_loss: 4.5758\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 6.7404 - val_loss: 1.2626\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 3.7492 - val_loss: 2.0567\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.4546 - val_loss: 1.8601\n",
      "114/114 [==============================] - 1s 743us/step\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 7.8589 - val_loss: 3.3399\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 9.3330 - val_loss: 2.4305\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.8015 - val_loss: 1.2845\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.9219 - val_loss: 2.0346\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.1154 - val_loss: 2.4549\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 3.8961 - val_loss: 2.1775\n",
      "114/114 [==============================] - 1s 752us/step\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 14.3701 - val_loss: 6.3426\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 9.8439 - val_loss: 3.1837\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.6912 - val_loss: 1.5191\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.6409 - val_loss: 1.9552\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.8924 - val_loss: 1.2773\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.9405 - val_loss: 1.3759\n",
      "114/114 [==============================] - 1s 885us/step\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 12.3551 - val_loss: 8.6159\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 9.6134 - val_loss: 2.7158\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 6.3367 - val_loss: 1.7386\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.7102 - val_loss: 1.4143\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.5173 - val_loss: 2.5838\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.0075 - val_loss: 1.1094\n",
      "114/114 [==============================] - 1s 752us/step\n",
      "Epoch 1/6\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 9.3980 - val_loss: 13.8921\n",
      "Epoch 2/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 12.6129 - val_loss: 3.2189\n",
      "Epoch 3/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.0743 - val_loss: 4.0431\n",
      "Epoch 4/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.5647 - val_loss: 1.6079\n",
      "Epoch 5/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.8346 - val_loss: 1.1718\n",
      "Epoch 6/6\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.2121 - val_loss: 3.7160\n",
      "114/114 [==============================] - 1s 867us/step\n",
      "Epoch: 6, Batch size: 24, Value: 1.0376650273193833\n",
      "Epoch 1/6\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 17.8706 - val_loss: 3.8180\n",
      "Epoch 2/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 9.1882 - val_loss: 9.0963\n",
      "Epoch 3/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 7.7542 - val_loss: 4.5534\n",
      "Epoch 4/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 5.4864 - val_loss: 5.3426\n",
      "Epoch 5/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 6.8074 - val_loss: 1.5061\n",
      "Epoch 6/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 5.2443 - val_loss: 1.1947\n",
      "114/114 [==============================] - 1s 858us/step\n",
      "Epoch 1/6\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 6.9974 - val_loss: 10.7491\n",
      "Epoch 2/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 11.9502 - val_loss: 6.2694\n",
      "Epoch 3/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 6.3625 - val_loss: 4.8830\n",
      "Epoch 4/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 6.5009 - val_loss: 2.9043\n",
      "Epoch 5/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 6.1775 - val_loss: 2.7747\n",
      "Epoch 6/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 6.3813 - val_loss: 1.6315\n",
      "114/114 [==============================] - 1s 823us/step\n",
      "Epoch 1/6\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 9.1562 - val_loss: 9.3530\n",
      "Epoch 2/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 11.7712 - val_loss: 2.6709\n",
      "Epoch 3/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 8.7613 - val_loss: 1.7347\n",
      "Epoch 4/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 6.3563 - val_loss: 3.1335\n",
      "Epoch 5/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 4.8244 - val_loss: 1.7746\n",
      "Epoch 6/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 6.5693 - val_loss: 1.9041\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch 1/6\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 11.6056 - val_loss: 6.7300\n",
      "Epoch 2/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 11.8287 - val_loss: 2.5160\n",
      "Epoch 3/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 4.6951 - val_loss: 3.4187\n",
      "Epoch 4/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 9.0479 - val_loss: 4.3298\n",
      "Epoch 5/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 5.2973 - val_loss: 2.2569\n",
      "Epoch 6/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 5.9088 - val_loss: 2.6338\n",
      "114/114 [==============================] - 1s 858us/step\n",
      "Epoch 1/6\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 11.3353 - val_loss: 9.9024\n",
      "Epoch 2/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 11.9408 - val_loss: 1.2857\n",
      "Epoch 3/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 10.2769 - val_loss: 1.9893\n",
      "Epoch 4/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 10.8764 - val_loss: 2.3104\n",
      "Epoch 5/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 5.5606 - val_loss: 3.4035\n",
      "Epoch 6/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 8.2034 - val_loss: 2.9456\n",
      "114/114 [==============================] - 1s 779us/step\n",
      "Epoch 1/6\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 10.8319 - val_loss: 5.7537\n",
      "Epoch 2/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 10.4946 - val_loss: 3.2678\n",
      "Epoch 3/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 8.1342 - val_loss: 5.5096\n",
      "Epoch 4/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 5.0940 - val_loss: 1.8323\n",
      "Epoch 5/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 5.9427 - val_loss: 1.5764\n",
      "Epoch 6/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 4.9761 - val_loss: 1.7129\n",
      "114/114 [==============================] - 1s 743us/step\n",
      "Epoch 1/6\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 10.7505 - val_loss: 1.9133\n",
      "Epoch 2/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 12.6243 - val_loss: 2.3645\n",
      "Epoch 3/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 11.4615 - val_loss: 3.2332\n",
      "Epoch 4/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 7.4084 - val_loss: 2.1537\n",
      "Epoch 5/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 7.0966 - val_loss: 1.6506\n",
      "Epoch 6/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 5.0529 - val_loss: 1.8861\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch 1/6\n",
      "797/797 [==============================] - 4s 3ms/step - loss: 16.2535 - val_loss: 6.6393\n",
      "Epoch 2/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 11.5731 - val_loss: 5.3579\n",
      "Epoch 3/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 11.8146 - val_loss: 1.9342\n",
      "Epoch 4/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 7.5318 - val_loss: 4.3545\n",
      "Epoch 5/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 7.0933 - val_loss: 5.5805\n",
      "Epoch 6/6\n",
      "797/797 [==============================] - 1s 1ms/step - loss: 5.5395 - val_loss: 4.1922\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch: 6, Batch size: 32, Value: 0.9304734732791309\n",
      "Epoch 1/6\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 14.1777 - val_loss: 16.1875\n",
      "Epoch 2/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 9.3468 - val_loss: 7.9972\n",
      "Epoch 3/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 11.1164 - val_loss: 4.0441\n",
      "Epoch 4/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.6829 - val_loss: 2.2945\n",
      "Epoch 5/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 6.3008 - val_loss: 1.5639\n",
      "Epoch 6/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 4.6748 - val_loss: 3.1689\n",
      "114/114 [==============================] - 1s 708us/step\n",
      "Epoch 1/6\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 12.0782 - val_loss: 3.8137\n",
      "Epoch 2/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 12.9471 - val_loss: 3.1063\n",
      "Epoch 3/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 8.5274 - val_loss: 1.5796\n",
      "Epoch 4/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.0805 - val_loss: 1.4973\n",
      "Epoch 5/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.1767 - val_loss: 1.3211\n",
      "Epoch 6/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 4.2727 - val_loss: 1.5226\n",
      "114/114 [==============================] - 1s 796us/step\n",
      "Epoch 1/6\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 18.5371 - val_loss: 1.3764\n",
      "Epoch 2/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 12.6936 - val_loss: 3.9284\n",
      "Epoch 3/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 13.9837 - val_loss: 2.9044\n",
      "Epoch 4/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 11.5302 - val_loss: 6.2154\n",
      "Epoch 5/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 16.3727 - val_loss: 2.9723\n",
      "Epoch 6/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 9.9011 - val_loss: 1.2990\n",
      "114/114 [==============================] - 1s 973us/step\n",
      "Epoch 1/6\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 23.5243 - val_loss: 2.0483\n",
      "Epoch 2/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 12.4265 - val_loss: 9.4336\n",
      "Epoch 3/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 9.4484 - val_loss: 1.4025\n",
      "Epoch 4/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 9.0522 - val_loss: 1.1751\n",
      "Epoch 5/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.1278 - val_loss: 3.5240\n",
      "Epoch 6/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 4.9200 - val_loss: 1.3530\n",
      "114/114 [==============================] - 0s 796us/step\n",
      "Epoch 1/6\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 13.4652 - val_loss: 2.5574\n",
      "Epoch 2/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 12.8705 - val_loss: 3.8575\n",
      "Epoch 3/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 4.6682 - val_loss: 2.6660\n",
      "Epoch 4/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 5.1750 - val_loss: 2.2143\n",
      "Epoch 5/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 4.8135 - val_loss: 1.1739\n",
      "Epoch 6/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 4.9276 - val_loss: 1.2890\n",
      "114/114 [==============================] - 1s 717us/step\n",
      "Epoch 1/6\n",
      "554/554 [==============================] - 4s 4ms/step - loss: 9.7454 - val_loss: 2.0745\n",
      "Epoch 2/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 11.5914 - val_loss: 2.4703\n",
      "Epoch 3/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 10.0838 - val_loss: 1.8937\n",
      "Epoch 4/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 6.1856 - val_loss: 1.5390\n",
      "Epoch 5/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.8456 - val_loss: 1.7994\n",
      "Epoch 6/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.2158 - val_loss: 1.2872\n",
      "114/114 [==============================] - 1s 761us/step\n",
      "Epoch 1/6\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 7.6576 - val_loss: 3.1136\n",
      "Epoch 2/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.6208 - val_loss: 4.2718\n",
      "Epoch 3/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 11.1299 - val_loss: 6.1999\n",
      "Epoch 4/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 9.5448 - val_loss: 2.1373\n",
      "Epoch 5/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 5.9016 - val_loss: 3.4801\n",
      "Epoch 6/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 4.4838 - val_loss: 1.7527\n",
      "114/114 [==============================] - 1s 735us/step\n",
      "Epoch 1/6\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 14.3266 - val_loss: 13.5105\n",
      "Epoch 2/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 25.8282 - val_loss: 3.1791\n",
      "Epoch 3/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 15.1327 - val_loss: 2.3021\n",
      "Epoch 4/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 14.5985 - val_loss: 4.7320\n",
      "Epoch 5/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 9.9679 - val_loss: 4.9811\n",
      "Epoch 6/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 11.0430 - val_loss: 5.1906\n",
      "114/114 [==============================] - 1s 788us/step\n",
      "Epoch 1/6\n",
      "554/554 [==============================] - 4s 4ms/step - loss: 13.8100 - val_loss: 4.7049\n",
      "Epoch 2/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 16.6966 - val_loss: 4.8747\n",
      "Epoch 3/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 13.4285 - val_loss: 3.2426\n",
      "Epoch 4/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 10.8040 - val_loss: 1.9300\n",
      "Epoch 5/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 6.5741 - val_loss: 3.6583\n",
      "Epoch 6/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 6.9982 - val_loss: 1.2546\n",
      "114/114 [==============================] - 0s 761us/step\n",
      "Epoch 1/6\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 14.6450 - val_loss: 6.8243\n",
      "Epoch 2/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.1909 - val_loss: 1.2861\n",
      "Epoch 3/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 8.0602 - val_loss: 2.5123\n",
      "Epoch 4/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 5.7550 - val_loss: 2.9775\n",
      "Epoch 5/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 5.7951 - val_loss: 1.4415\n",
      "Epoch 6/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 4.2829 - val_loss: 1.2497\n",
      "114/114 [==============================] - 0s 796us/step\n",
      "Epoch 1/6\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 15.1443 - val_loss: 3.6343\n",
      "Epoch 2/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 17.7813 - val_loss: 1.7093\n",
      "Epoch 3/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 12.4431 - val_loss: 5.7050\n",
      "Epoch 4/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 11.1177 - val_loss: 2.3911\n",
      "Epoch 5/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 6.6748 - val_loss: 1.3237\n",
      "Epoch 6/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.7039 - val_loss: 2.1472\n",
      "114/114 [==============================] - 0s 920us/step\n",
      "Epoch 1/6\n",
      "554/554 [==============================] - 4s 3ms/step - loss: 9.7688 - val_loss: 4.3588\n",
      "Epoch 2/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 11.8506 - val_loss: 1.9339\n",
      "Epoch 3/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 10.5877 - val_loss: 1.8479\n",
      "Epoch 4/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 6.4708 - val_loss: 4.8240\n",
      "Epoch 5/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 7.7649 - val_loss: 1.9633\n",
      "Epoch 6/6\n",
      "554/554 [==============================] - 1s 1ms/step - loss: 4.6409 - val_loss: 5.7073\n",
      "114/114 [==============================] - 1s 788us/step\n",
      "Epoch: 6, Batch size: 46, Value: 0.8583441710882095\n",
      "Epoch 1/6\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 48.3987 - val_loss: 5.4063\n",
      "Epoch 2/6\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 11.0364 - val_loss: 2.6820\n",
      "Epoch 3/6\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 9.2864 - val_loss: 6.3555\n",
      "Epoch 4/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 12.2951 - val_loss: 2.2146\n",
      "Epoch 5/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 7.9688 - val_loss: 1.8712\n",
      "Epoch 6/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 10.1142 - val_loss: 1.2665\n",
      "114/114 [==============================] - 1s 850us/step\n",
      "Epoch 1/6\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 8.7670 - val_loss: 7.6029\n",
      "Epoch 2/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 14.2067 - val_loss: 2.7569\n",
      "Epoch 3/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 7.0729 - val_loss: 1.3946\n",
      "Epoch 4/6\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 12.8730 - val_loss: 2.4601\n",
      "Epoch 5/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 6.5316 - val_loss: 1.9648\n",
      "Epoch 6/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 7.2887 - val_loss: 3.4834\n",
      "114/114 [==============================] - 1s 735us/step\n",
      "Epoch 1/6\n",
      "399/399 [==============================] - 3s 2ms/step - loss: 18.1418 - val_loss: 8.9114\n",
      "Epoch 2/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 20.3438 - val_loss: 2.6243\n",
      "Epoch 3/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 13.9881 - val_loss: 2.3748\n",
      "Epoch 4/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 10.2844 - val_loss: 2.7016\n",
      "Epoch 5/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 10.9586 - val_loss: 6.0045\n",
      "Epoch 6/6\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 17.6714 - val_loss: 7.3826\n",
      "114/114 [==============================] - 1s 681us/step\n",
      "Epoch 1/6\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 11.3631 - val_loss: 9.7724\n",
      "Epoch 2/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 14.5056 - val_loss: 2.8841\n",
      "Epoch 3/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 7.3538 - val_loss: 2.5719\n",
      "Epoch 4/6\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 6.2882 - val_loss: 1.4386\n",
      "Epoch 5/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 6.7572 - val_loss: 2.6037\n",
      "Epoch 6/6\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 7.1765 - val_loss: 1.5253\n",
      "114/114 [==============================] - 1s 796us/step\n",
      "Epoch 1/6\n",
      "399/399 [==============================] - 4s 4ms/step - loss: 15.5148 - val_loss: 2.1477\n",
      "Epoch 2/6\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 11.3435 - val_loss: 4.2972\n",
      "Epoch 3/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 16.7383 - val_loss: 8.3936\n",
      "Epoch 4/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 13.6059 - val_loss: 2.9268\n",
      "Epoch 5/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 9.4689 - val_loss: 1.5389\n",
      "Epoch 6/6\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 5.7561 - val_loss: 3.5600\n",
      "114/114 [==============================] - 1s 858us/step\n",
      "Epoch: 6, Batch size: 64, Value: 1.112378024425139\n",
      "Epoch 1/6\n",
      "266/266 [==============================] - 4s 6ms/step - loss: 19.4967 - val_loss: 58.6369\n",
      "Epoch 2/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 26.5540 - val_loss: 37.2075\n",
      "Epoch 3/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 13.3760 - val_loss: 29.6912\n",
      "Epoch 4/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 10.7775 - val_loss: 31.5070\n",
      "Epoch 5/6\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 10.7132 - val_loss: 29.2196\n",
      "Epoch 6/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 16.3921 - val_loss: 18.1294\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch 1/6\n",
      "266/266 [==============================] - 4s 6ms/step - loss: 13.3051 - val_loss: 3.5642\n",
      "Epoch 2/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 20.0460 - val_loss: 6.9454\n",
      "Epoch 3/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 10.6046 - val_loss: 14.4395\n",
      "Epoch 4/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 12.3995 - val_loss: 4.4587\n",
      "Epoch 5/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 9.0251 - val_loss: 1.5838\n",
      "Epoch 6/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 4.3458 - val_loss: 3.1645\n",
      "114/114 [==============================] - 1s 717us/step\n",
      "Epoch 1/6\n",
      "266/266 [==============================] - 3s 2ms/step - loss: 27.2944 - val_loss: 4.5131\n",
      "Epoch 2/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 9.9547 - val_loss: 2.2650\n",
      "Epoch 3/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 5.7378 - val_loss: 2.8443\n",
      "Epoch 4/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 8.5748 - val_loss: 2.1769\n",
      "Epoch 5/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 5.0256 - val_loss: 1.3707\n",
      "Epoch 6/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 6.2904 - val_loss: 4.3120\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch 1/6\n",
      "266/266 [==============================] - 4s 6ms/step - loss: 10.0397 - val_loss: 1.9676\n",
      "Epoch 2/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 12.9782 - val_loss: 3.2751\n",
      "Epoch 3/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 12.5212 - val_loss: 5.1968\n",
      "Epoch 4/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 14.9341 - val_loss: 9.0800\n",
      "Epoch 5/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 12.0784 - val_loss: 1.4698\n",
      "Epoch 6/6\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 4.6647 - val_loss: 2.6854\n",
      "114/114 [==============================] - 1s 832us/step\n",
      "Epoch: 6, Batch size: 96, Value: 2.19257145245926\n",
      "Epoch 1/6\n",
      "200/200 [==============================] - 4s 7ms/step - loss: 37.6573 - val_loss: 43.5274\n",
      "Epoch 2/6\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 34.0602 - val_loss: 38.3054\n",
      "Epoch 3/6\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 29.9222 - val_loss: 38.3584\n",
      "Epoch 4/6\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 25.6510 - val_loss: 32.1839\n",
      "Epoch 5/6\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 21.5335 - val_loss: 16.8515\n",
      "Epoch 6/6\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 11.9476 - val_loss: 16.2470\n",
      "114/114 [==============================] - 1s 726us/step\n",
      "Epoch 1/6\n",
      "200/200 [==============================] - 4s 7ms/step - loss: 12.3046 - val_loss: 8.8736\n",
      "Epoch 2/6\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 22.6394 - val_loss: 2.1883\n",
      "Epoch 3/6\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 19.2843 - val_loss: 4.6610\n",
      "Epoch 4/6\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 24.5989 - val_loss: 1.6866\n",
      "Epoch 5/6\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 17.5142 - val_loss: 18.3779\n",
      "Epoch 6/6\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 19.4788 - val_loss: 16.3758\n",
      "114/114 [==============================] - 1s 814us/step\n",
      "Epoch 1/6\n",
      "200/200 [==============================] - 4s 7ms/step - loss: 35.7245 - val_loss: 20.9939\n",
      "Epoch 2/6\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 23.8603 - val_loss: 12.8235\n",
      "Epoch 3/6\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 17.4225 - val_loss: 21.3947\n",
      "Epoch 4/6\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 17.2556 - val_loss: 19.5377\n",
      "Epoch 5/6\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 18.8306 - val_loss: 13.5161\n",
      "Epoch 6/6\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 15.1751 - val_loss: 7.7638\n",
      "114/114 [==============================] - 1s 982us/step\n",
      "Epoch: 6, Batch size: 128, Value: 5.424295212623529\n",
      "Epoch 1/6\n",
      "100/100 [==============================] - 4s 13ms/step - loss: 40.4112 - val_loss: 7.3131\n",
      "Epoch 2/6\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.7331 - val_loss: 11.5514\n",
      "Epoch 3/6\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.2389 - val_loss: 15.7044\n",
      "Epoch 4/6\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.3026 - val_loss: 11.4137\n",
      "Epoch 5/6\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 11.2894 - val_loss: 5.0721\n",
      "Epoch 6/6\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 7.9244 - val_loss: 5.7401\n",
      "114/114 [==============================] - 1s 726us/step\n",
      "Epoch 1/6\n",
      "100/100 [==============================] - 4s 13ms/step - loss: 22.0631 - val_loss: 16.8680\n",
      "Epoch 2/6\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.2167 - val_loss: 18.6643\n",
      "Epoch 3/6\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.8572 - val_loss: 23.2125\n",
      "Epoch 4/6\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.7907 - val_loss: 26.7021\n",
      "Epoch 5/6\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 50.6761 - val_loss: 17.3310\n",
      "Epoch 6/6\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 82.6095 - val_loss: 2.7625\n",
      "114/114 [==============================] - 1s 734us/step\n",
      "Epoch 1/6\n",
      "100/100 [==============================] - 4s 17ms/step - loss: 33.8919 - val_loss: 17.4938\n",
      "Epoch 2/6\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.7180 - val_loss: 19.0482\n",
      "Epoch 3/6\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.6427 - val_loss: 7.2629\n",
      "Epoch 4/6\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.2084 - val_loss: 10.3544\n",
      "Epoch 5/6\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.9735 - val_loss: 5.1673\n",
      "Epoch 6/6\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.5480 - val_loss: 8.7158\n",
      "114/114 [==============================] - 1s 876us/step\n",
      "Epoch: 6, Batch size: 256, Value: 6.470955466126445\n",
      "Epoch 1/7\n",
      "6369/6369 [==============================] - 11s 1ms/step - loss: 6.9497 - val_loss: 24.5547\n",
      "Epoch 2/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 4.1020 - val_loss: 13.7206\n",
      "Epoch 3/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.9133 - val_loss: 9.0184\n",
      "Epoch 4/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.5604 - val_loss: 6.9000\n",
      "Epoch 5/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.3178 - val_loss: 5.9795\n",
      "Epoch 6/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.2681 - val_loss: 5.8153\n",
      "Epoch 7/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.1315 - val_loss: 5.6682\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch 1/7\n",
      "6369/6369 [==============================] - 10s 1ms/step - loss: 6.5448 - val_loss: 17.5974\n",
      "Epoch 2/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.7667 - val_loss: 9.3289\n",
      "Epoch 3/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.9521 - val_loss: 4.1362\n",
      "Epoch 4/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.6945 - val_loss: 4.8965\n",
      "Epoch 5/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.4088 - val_loss: 4.4346\n",
      "Epoch 6/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.2124 - val_loss: 4.1825\n",
      "Epoch 7/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.0990 - val_loss: 3.5576\n",
      "114/114 [==============================] - 1s 708us/step\n",
      "Epoch 1/7\n",
      "6369/6369 [==============================] - 11s 1ms/step - loss: 7.8408 - val_loss: 25.7349\n",
      "Epoch 2/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 4.2932 - val_loss: 14.6029\n",
      "Epoch 3/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.1171 - val_loss: 7.4348\n",
      "Epoch 4/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 3.1528 - val_loss: 3.5548\n",
      "Epoch 5/7\n",
      "6369/6369 [==============================] - 8s 1ms/step - loss: 2.6590 - val_loss: 4.5934\n",
      "Epoch 6/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.4528 - val_loss: 3.7666\n",
      "Epoch 7/7\n",
      "6369/6369 [==============================] - 7s 1ms/step - loss: 2.2916 - val_loss: 3.9340\n",
      "114/114 [==============================] - 1s 788us/step\n",
      "Epoch: 7, Batch size: 4, Value: 5.924925135094196\n",
      "Epoch 1/7\n",
      "4246/4246 [==============================] - 9s 1ms/step - loss: 8.8028 - val_loss: 23.0972\n",
      "Epoch 2/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 5.5110 - val_loss: 14.5118\n",
      "Epoch 3/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.5633 - val_loss: 7.0527\n",
      "Epoch 4/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.9269 - val_loss: 3.3789\n",
      "Epoch 5/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.7881 - val_loss: 4.5261\n",
      "Epoch 6/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.5873 - val_loss: 4.1119\n",
      "Epoch 7/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.3904 - val_loss: 3.6421\n",
      "114/114 [==============================] - 1s 752us/step\n",
      "Epoch 1/7\n",
      "4246/4246 [==============================] - 8s 1ms/step - loss: 5.7827 - val_loss: 18.9109\n",
      "Epoch 2/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 4.5281 - val_loss: 14.1249\n",
      "Epoch 3/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.4805 - val_loss: 9.5813\n",
      "Epoch 4/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.9748 - val_loss: 4.5315\n",
      "Epoch 5/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.9286 - val_loss: 4.2125\n",
      "Epoch 6/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.7756 - val_loss: 2.6906\n",
      "Epoch 7/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.6145 - val_loss: 3.1203\n",
      "114/114 [==============================] - 1s 708us/step\n",
      "Epoch 1/7\n",
      "4246/4246 [==============================] - 8s 1ms/step - loss: 5.8773 - val_loss: 12.3171\n",
      "Epoch 2/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.9867 - val_loss: 7.0458\n",
      "Epoch 3/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.6344 - val_loss: 4.4818\n",
      "Epoch 4/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.5867 - val_loss: 4.8654\n",
      "Epoch 5/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.1479 - val_loss: 2.0141\n",
      "Epoch 6/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.7141 - val_loss: 2.7055\n",
      "Epoch 7/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.4414 - val_loss: 2.5031\n",
      "114/114 [==============================] - 1s 805us/step\n",
      "Epoch 1/7\n",
      "4246/4246 [==============================] - 8s 1ms/step - loss: 12.4535 - val_loss: 30.7445\n",
      "Epoch 2/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 7.7379 - val_loss: 20.3452\n",
      "Epoch 3/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 4.0689 - val_loss: 7.7566\n",
      "Epoch 4/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 3.1626 - val_loss: 5.5170\n",
      "Epoch 5/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.7772 - val_loss: 4.8076\n",
      "Epoch 6/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.6070 - val_loss: 4.3605\n",
      "Epoch 7/7\n",
      "4246/4246 [==============================] - 5s 1ms/step - loss: 2.4906 - val_loss: 4.3167\n",
      "114/114 [==============================] - 1s 982us/step\n",
      "Epoch: 7, Batch size: 6, Value: 2.8416316457931576\n",
      "Epoch 1/7\n",
      "3185/3185 [==============================] - 7s 2ms/step - loss: 7.6923 - val_loss: 21.4710\n",
      "Epoch 2/7\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 4.7861 - val_loss: 7.8239\n",
      "Epoch 3/7\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 3.1897 - val_loss: 6.5037\n",
      "Epoch 4/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.0520 - val_loss: 3.8658\n",
      "Epoch 5/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.7853 - val_loss: 1.3065\n",
      "Epoch 6/7\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 2.5949 - val_loss: 1.4781\n",
      "Epoch 7/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.4799 - val_loss: 1.7623\n",
      "114/114 [==============================] - 1s 850us/step\n",
      "Epoch 1/7\n",
      "3185/3185 [==============================] - 7s 2ms/step - loss: 10.1548 - val_loss: 29.6790\n",
      "Epoch 2/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 6.6580 - val_loss: 20.7492\n",
      "Epoch 3/7\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 4.2483 - val_loss: 11.8986\n",
      "Epoch 4/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.7995 - val_loss: 9.2606\n",
      "Epoch 5/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.3053 - val_loss: 3.5771\n",
      "Epoch 6/7\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 3.0554 - val_loss: 2.1345\n",
      "Epoch 7/7\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 2.6353 - val_loss: 1.3724\n",
      "114/114 [==============================] - 1s 779us/step\n",
      "Epoch 1/7\n",
      "3185/3185 [==============================] - 7s 2ms/step - loss: 11.8748 - val_loss: 12.3258\n",
      "Epoch 2/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 7.9677 - val_loss: 16.0304\n",
      "Epoch 3/7\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 4.6579 - val_loss: 13.8411\n",
      "Epoch 4/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.3122 - val_loss: 5.4407\n",
      "Epoch 5/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.6344 - val_loss: 2.5337\n",
      "Epoch 6/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.4936 - val_loss: 1.4315\n",
      "Epoch 7/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.4518 - val_loss: 1.7305\n",
      "114/114 [==============================] - 1s 938us/step\n",
      "Epoch 1/7\n",
      "3185/3185 [==============================] - 7s 2ms/step - loss: 10.9753 - val_loss: 29.7969\n",
      "Epoch 2/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 7.5800 - val_loss: 26.4796\n",
      "Epoch 3/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 5.2027 - val_loss: 18.4581\n",
      "Epoch 4/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.6580 - val_loss: 10.9025\n",
      "Epoch 5/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.1067 - val_loss: 7.6503\n",
      "Epoch 6/7\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 2.6279 - val_loss: 2.2252\n",
      "Epoch 7/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.4375 - val_loss: 1.7729\n",
      "114/114 [==============================] - 1s 885us/step\n",
      "Epoch 1/7\n",
      "3185/3185 [==============================] - 6s 1ms/step - loss: 9.4158 - val_loss: 20.2159\n",
      "Epoch 2/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 7.3669 - val_loss: 10.5772\n",
      "Epoch 3/7\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 4.4434 - val_loss: 5.8556\n",
      "Epoch 4/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.4961 - val_loss: 5.3985\n",
      "Epoch 5/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.6250 - val_loss: 6.0864\n",
      "Epoch 6/7\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 3.1570 - val_loss: 1.9277\n",
      "Epoch 7/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.7847 - val_loss: 2.3170\n",
      "114/114 [==============================] - 1s 796us/step\n",
      "Epoch 1/7\n",
      "3185/3185 [==============================] - 7s 2ms/step - loss: 7.2823 - val_loss: 27.6670\n",
      "Epoch 2/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.8863 - val_loss: 11.9263\n",
      "Epoch 3/7\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 3.6073 - val_loss: 9.0197\n",
      "Epoch 4/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.0755 - val_loss: 7.8106\n",
      "Epoch 5/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.6524 - val_loss: 5.6711\n",
      "Epoch 6/7\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 2.4599 - val_loss: 5.3662\n",
      "Epoch 7/7\n",
      "3185/3185 [==============================] - 3s 1ms/step - loss: 2.3890 - val_loss: 5.1294\n",
      "114/114 [==============================] - 1s 770us/step\n",
      "Epoch 1/7\n",
      "3185/3185 [==============================] - 7s 2ms/step - loss: 8.1329 - val_loss: 19.6448\n",
      "Epoch 2/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 6.3033 - val_loss: 12.0777\n",
      "Epoch 3/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.8561 - val_loss: 6.8851\n",
      "Epoch 4/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.2805 - val_loss: 4.3054\n",
      "Epoch 5/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.7805 - val_loss: 2.8934\n",
      "Epoch 6/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.5936 - val_loss: 2.8071\n",
      "Epoch 7/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.6791 - val_loss: 1.1930\n",
      "114/114 [==============================] - 0s 982us/step\n",
      "Epoch 1/7\n",
      "3185/3185 [==============================] - 7s 2ms/step - loss: 10.3403 - val_loss: 17.5930\n",
      "Epoch 2/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 5.0914 - val_loss: 6.7514\n",
      "Epoch 3/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 4.0146 - val_loss: 1.5115\n",
      "Epoch 4/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.5713 - val_loss: 2.2752\n",
      "Epoch 5/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 3.1837 - val_loss: 3.6447\n",
      "Epoch 6/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.8530 - val_loss: 3.3687\n",
      "Epoch 7/7\n",
      "3185/3185 [==============================] - 4s 1ms/step - loss: 2.6542 - val_loss: 3.4161\n",
      "114/114 [==============================] - 1s 814us/step\n",
      "Epoch: 7, Batch size: 8, Value: 0.8346030368438463\n",
      "Epoch 1/7\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 9.2679 - val_loss: 19.8508\n",
      "Epoch 2/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 7.9185 - val_loss: 14.7834\n",
      "Epoch 3/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 4.6065 - val_loss: 8.5999\n",
      "Epoch 4/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.6978 - val_loss: 7.5027\n",
      "Epoch 5/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.3978 - val_loss: 3.8350\n",
      "Epoch 6/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 3.3283 - val_loss: 1.6645\n",
      "Epoch 7/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 3.1744 - val_loss: 1.5860\n",
      "114/114 [==============================] - 1s 743us/step\n",
      "Epoch 1/7\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 8.3851 - val_loss: 19.4733\n",
      "Epoch 2/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 6.1568 - val_loss: 11.7163\n",
      "Epoch 3/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 4.8427 - val_loss: 8.6210\n",
      "Epoch 4/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.8399 - val_loss: 5.2760\n",
      "Epoch 5/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 3.6254 - val_loss: 3.0286\n",
      "Epoch 6/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 3.2623 - val_loss: 2.5102\n",
      "Epoch 7/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 2.9340 - val_loss: 2.9413\n",
      "114/114 [==============================] - 1s 956us/step\n",
      "Epoch 1/7\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 10.6282 - val_loss: 8.6792\n",
      "Epoch 2/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 5.7227 - val_loss: 4.0390\n",
      "Epoch 3/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 4.6992 - val_loss: 7.0618\n",
      "Epoch 4/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 3.3544 - val_loss: 4.3715\n",
      "Epoch 5/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 2.9247 - val_loss: 4.6362\n",
      "Epoch 6/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.0501 - val_loss: 1.1303\n",
      "Epoch 7/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 2.4170 - val_loss: 1.1599\n",
      "114/114 [==============================] - 1s 814us/step\n",
      "Epoch 1/7\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 8.6262 - val_loss: 26.0466\n",
      "Epoch 2/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 6.3272 - val_loss: 14.9159\n",
      "Epoch 3/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 4.4731 - val_loss: 9.7861\n",
      "Epoch 4/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 3.5060 - val_loss: 9.8568\n",
      "Epoch 5/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 2.9779 - val_loss: 8.0442\n",
      "Epoch 6/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 2.9265 - val_loss: 6.5648\n",
      "Epoch 7/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 2.8179 - val_loss: 6.3112\n",
      "114/114 [==============================] - 1s 894us/step\n",
      "Epoch 1/7\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 8.5437 - val_loss: 25.2280\n",
      "Epoch 2/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 6.7426 - val_loss: 18.6482\n",
      "Epoch 3/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 4.9851 - val_loss: 10.6594\n",
      "Epoch 4/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 3.6435 - val_loss: 8.5638\n",
      "Epoch 5/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 3.2230 - val_loss: 4.7817\n",
      "Epoch 6/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 2.6029 - val_loss: 2.3985\n",
      "Epoch 7/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 2.7193 - val_loss: 1.1624\n",
      "114/114 [==============================] - 2s 752us/step\n",
      "Epoch 1/7\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 10.3828 - val_loss: 8.7813\n",
      "Epoch 2/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 7.3279 - val_loss: 9.2161\n",
      "Epoch 3/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 4.6245 - val_loss: 2.9743\n",
      "Epoch 4/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 4.2365 - val_loss: 5.0422\n",
      "Epoch 5/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 3.5368 - val_loss: 1.6703\n",
      "Epoch 6/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 3.1456 - val_loss: 1.2173\n",
      "Epoch 7/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 3.8115 - val_loss: 1.6395\n",
      "114/114 [==============================] - 1s 809us/step\n",
      "Epoch 1/7\n",
      "2123/2123 [==============================] - 6s 2ms/step - loss: 10.3847 - val_loss: 20.4172\n",
      "Epoch 2/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 7.6419 - val_loss: 17.3486\n",
      "Epoch 3/7\n",
      "2123/2123 [==============================] - 2s 1ms/step - loss: 5.2286 - val_loss: 11.1884\n",
      "Epoch 4/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 3.7662 - val_loss: 8.9205\n",
      "Epoch 5/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 3.1644 - val_loss: 6.0622\n",
      "Epoch 6/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 2.6538 - val_loss: 5.3400\n",
      "Epoch 7/7\n",
      "2123/2123 [==============================] - 3s 1ms/step - loss: 2.5449 - val_loss: 5.6584\n",
      "114/114 [==============================] - 1s 741us/step\n",
      "Epoch: 7, Batch size: 12, Value: 0.8219343266649812\n",
      "Epoch 1/7\n",
      "1593/1593 [==============================] - 5s 2ms/step - loss: 9.5148 - val_loss: 6.0790\n",
      "Epoch 2/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 7.5581 - val_loss: 4.4052\n",
      "Epoch 3/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.6987 - val_loss: 7.9299\n",
      "Epoch 4/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.4313 - val_loss: 5.5082\n",
      "Epoch 5/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.6012 - val_loss: 4.0286\n",
      "Epoch 6/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 3.9434 - val_loss: 1.2924\n",
      "Epoch 7/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.4061 - val_loss: 2.8556\n",
      "114/114 [==============================] - 1s 734us/step\n",
      "Epoch 1/7\n",
      "1593/1593 [==============================] - 5s 2ms/step - loss: 8.6630 - val_loss: 15.6774\n",
      "Epoch 2/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 8.7349 - val_loss: 11.0215\n",
      "Epoch 3/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.7214 - val_loss: 10.0080\n",
      "Epoch 4/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.1487 - val_loss: 5.6132\n",
      "Epoch 5/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 3.5945 - val_loss: 5.6662\n",
      "Epoch 6/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 3.1335 - val_loss: 4.8191\n",
      "Epoch 7/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 2.9251 - val_loss: 5.0876\n",
      "114/114 [==============================] - 1s 761us/step\n",
      "Epoch 1/7\n",
      "1593/1593 [==============================] - 6s 2ms/step - loss: 7.3571 - val_loss: 7.2574\n",
      "Epoch 2/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 6.3192 - val_loss: 9.3165\n",
      "Epoch 3/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 5.8471 - val_loss: 4.7543\n",
      "Epoch 4/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.7005 - val_loss: 7.4788\n",
      "Epoch 5/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 4.3281 - val_loss: 7.2993\n",
      "Epoch 6/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 3.6935 - val_loss: 4.8420\n",
      "Epoch 7/7\n",
      "1593/1593 [==============================] - 2s 1ms/step - loss: 3.7372 - val_loss: 2.8652\n",
      "114/114 [==============================] - 0s 930us/step\n",
      "Epoch: 7, Batch size: 16, Value: 3.2971447199728887\n",
      "Epoch 1/7\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 14.1135 - val_loss: 2.1618\n",
      "Epoch 2/7\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 14.7586 - val_loss: 1.6534\n",
      "Epoch 3/7\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 9.0190 - val_loss: 2.8891\n",
      "Epoch 4/7\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 8.3610 - val_loss: 2.9443\n",
      "Epoch 5/7\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.6495 - val_loss: 2.4740\n",
      "Epoch 6/7\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.8036 - val_loss: 1.9803\n",
      "Epoch 7/7\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.5255 - val_loss: 1.9992\n",
      "114/114 [==============================] - 1s 735us/step\n",
      "Epoch 1/7\n",
      "1062/1062 [==============================] - 5s 2ms/step - loss: 11.0154 - val_loss: 4.2169\n",
      "Epoch 2/7\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 9.4103 - val_loss: 1.5698\n",
      "Epoch 3/7\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 7.4491 - val_loss: 1.8189\n",
      "Epoch 4/7\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.6882 - val_loss: 1.8611\n",
      "Epoch 5/7\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 5.3482 - val_loss: 1.7618\n",
      "Epoch 6/7\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 4.4450 - val_loss: 1.2967\n",
      "Epoch 7/7\n",
      "1062/1062 [==============================] - 1s 1ms/step - loss: 3.7261 - val_loss: 1.5853\n"
     ]
    }
   ],
   "source": [
    "data = opti_rd_h(7, 16, 3, 15, [4, 6, 8, 12, 16, 24, 32, 46, 64, 96, 128, 256])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
