{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-12 03:00:00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.25</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-12 04:00:00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.15</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-12 05:00:00</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.30</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-12 06:00:00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.30</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-12 07:00:00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  open  high   low  close  value\n",
       "0  2020-08-12 03:00:00  3.10  3.35  3.10   3.25     75\n",
       "1  2020-08-12 04:00:00  3.25  3.25  3.15   3.15     75\n",
       "2  2020-08-12 05:00:00  3.15  3.30  3.15   3.30     75\n",
       "3  2020-08-12 06:00:00  3.30  3.30  3.15   3.30     75\n",
       "4  2020-08-12 07:00:00  3.25  3.25  3.20   3.25     75"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SolAtasIMC_tratado.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36400 entries, 0 to 36399\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   date    36400 non-null  object \n",
      " 1   open    36400 non-null  float64\n",
      " 2   high    36400 non-null  float64\n",
      " 3   low     36400 non-null  float64\n",
      " 4   close   36400 non-null  float64\n",
      " 5   value   36400 non-null  int64  \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanio = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-12 03:00:00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.25</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-12 04:00:00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.15</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-12 05:00:00</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.30</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-12 06:00:00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.30</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-12 07:00:00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25476</th>\n",
       "      <td>2023-07-11 21:00:00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.05</td>\n",
       "      <td>21.90</td>\n",
       "      <td>22.00</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25477</th>\n",
       "      <td>2023-07-11 22:00:00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.10</td>\n",
       "      <td>21.90</td>\n",
       "      <td>22.00</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25478</th>\n",
       "      <td>2023-07-11 23:00:00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.05</td>\n",
       "      <td>21.75</td>\n",
       "      <td>21.95</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25479</th>\n",
       "      <td>2023-07-12 00:00:00</td>\n",
       "      <td>21.95</td>\n",
       "      <td>22.10</td>\n",
       "      <td>21.90</td>\n",
       "      <td>22.05</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25480</th>\n",
       "      <td>2023-07-12 01:00:00</td>\n",
       "      <td>22.05</td>\n",
       "      <td>22.15</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.10</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25481 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date   open   high    low  close  value\n",
       "0      2020-08-12 03:00:00   3.10   3.35   3.10   3.25     75\n",
       "1      2020-08-12 04:00:00   3.25   3.25   3.15   3.15     75\n",
       "2      2020-08-12 05:00:00   3.15   3.30   3.15   3.30     75\n",
       "3      2020-08-12 06:00:00   3.30   3.30   3.15   3.30     75\n",
       "4      2020-08-12 07:00:00   3.25   3.25   3.20   3.25     75\n",
       "...                    ...    ...    ...    ...    ...    ...\n",
       "25476  2023-07-11 21:00:00  22.00  22.05  21.90  22.00     57\n",
       "25477  2023-07-11 22:00:00  22.00  22.10  21.90  22.00     57\n",
       "25478  2023-07-11 23:00:00  22.00  22.05  21.75  21.95     57\n",
       "25479  2023-07-12 00:00:00  21.95  22.10  21.90  22.05     64\n",
       "25480  2023-07-12 01:00:00  22.05  22.15  22.00  22.10     64\n",
       "\n",
       "[25481 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.copy().loc[0:int(tamanio*0.7)]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25481</th>\n",
       "      <td>2023-07-12 02:00:00</td>\n",
       "      <td>22.10</td>\n",
       "      <td>22.30</td>\n",
       "      <td>22.05</td>\n",
       "      <td>22.15</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482</th>\n",
       "      <td>2023-07-12 03:00:00</td>\n",
       "      <td>22.15</td>\n",
       "      <td>22.25</td>\n",
       "      <td>22.10</td>\n",
       "      <td>22.10</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25483</th>\n",
       "      <td>2023-07-12 04:00:00</td>\n",
       "      <td>22.10</td>\n",
       "      <td>22.10</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25484</th>\n",
       "      <td>2023-07-12 05:00:00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>21.90</td>\n",
       "      <td>21.95</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25485</th>\n",
       "      <td>2023-07-12 06:00:00</td>\n",
       "      <td>21.95</td>\n",
       "      <td>22.05</td>\n",
       "      <td>21.90</td>\n",
       "      <td>22.00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32756</th>\n",
       "      <td>2024-05-10 05:00:00</td>\n",
       "      <td>153.65</td>\n",
       "      <td>154.35</td>\n",
       "      <td>152.85</td>\n",
       "      <td>153.95</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32757</th>\n",
       "      <td>2024-05-10 06:00:00</td>\n",
       "      <td>153.95</td>\n",
       "      <td>154.70</td>\n",
       "      <td>153.45</td>\n",
       "      <td>153.75</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32758</th>\n",
       "      <td>2024-05-10 07:00:00</td>\n",
       "      <td>153.75</td>\n",
       "      <td>154.10</td>\n",
       "      <td>152.30</td>\n",
       "      <td>153.30</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32759</th>\n",
       "      <td>2024-05-10 08:00:00</td>\n",
       "      <td>153.30</td>\n",
       "      <td>155.10</td>\n",
       "      <td>153.15</td>\n",
       "      <td>154.95</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32760</th>\n",
       "      <td>2024-05-10 09:00:00</td>\n",
       "      <td>154.95</td>\n",
       "      <td>155.75</td>\n",
       "      <td>154.25</td>\n",
       "      <td>154.35</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7280 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date    open    high     low   close  value\n",
       "25481  2023-07-12 02:00:00   22.10   22.30   22.05   22.15     64\n",
       "25482  2023-07-12 03:00:00   22.15   22.25   22.10   22.10     64\n",
       "25483  2023-07-12 04:00:00   22.10   22.10   22.00   22.00     64\n",
       "25484  2023-07-12 05:00:00   22.00   22.00   21.90   21.95     64\n",
       "25485  2023-07-12 06:00:00   21.95   22.05   21.90   22.00     64\n",
       "...                    ...     ...     ...     ...     ...    ...\n",
       "32756  2024-05-10 05:00:00  153.65  154.35  152.85  153.95     66\n",
       "32757  2024-05-10 06:00:00  153.95  154.70  153.45  153.75     66\n",
       "32758  2024-05-10 07:00:00  153.75  154.10  152.30  153.30     66\n",
       "32759  2024-05-10 08:00:00  153.30  155.10  153.15  154.95     66\n",
       "32760  2024-05-10 09:00:00  154.95  155.75  154.25  154.35     66\n",
       "\n",
       "[7280 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vali = df.copy().loc[int(tamanio*0.7 + 1):int(tamanio*0.9)]\n",
    "df_vali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32761</th>\n",
       "      <td>2024-05-10 10:00:00</td>\n",
       "      <td>154.35</td>\n",
       "      <td>154.5</td>\n",
       "      <td>153.45</td>\n",
       "      <td>154.10</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32762</th>\n",
       "      <td>2024-05-10 11:00:00</td>\n",
       "      <td>154.10</td>\n",
       "      <td>154.8</td>\n",
       "      <td>153.25</td>\n",
       "      <td>154.15</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32763</th>\n",
       "      <td>2024-05-10 12:00:00</td>\n",
       "      <td>154.15</td>\n",
       "      <td>154.3</td>\n",
       "      <td>153.25</td>\n",
       "      <td>154.15</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32764</th>\n",
       "      <td>2024-05-10 13:00:00</td>\n",
       "      <td>154.15</td>\n",
       "      <td>155.2</td>\n",
       "      <td>153.00</td>\n",
       "      <td>155.05</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32765</th>\n",
       "      <td>2024-05-10 14:00:00</td>\n",
       "      <td>155.05</td>\n",
       "      <td>155.4</td>\n",
       "      <td>153.10</td>\n",
       "      <td>153.30</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36395</th>\n",
       "      <td>2024-10-08 20:00:00</td>\n",
       "      <td>143.35</td>\n",
       "      <td>143.9</td>\n",
       "      <td>142.35</td>\n",
       "      <td>142.95</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36396</th>\n",
       "      <td>2024-10-08 21:00:00</td>\n",
       "      <td>142.95</td>\n",
       "      <td>144.1</td>\n",
       "      <td>142.25</td>\n",
       "      <td>143.75</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36397</th>\n",
       "      <td>2024-10-08 22:00:00</td>\n",
       "      <td>143.75</td>\n",
       "      <td>144.5</td>\n",
       "      <td>143.35</td>\n",
       "      <td>144.50</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36398</th>\n",
       "      <td>2024-10-08 23:00:00</td>\n",
       "      <td>144.50</td>\n",
       "      <td>144.7</td>\n",
       "      <td>144.05</td>\n",
       "      <td>144.25</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36399</th>\n",
       "      <td>2024-10-09 00:00:00</td>\n",
       "      <td>144.25</td>\n",
       "      <td>144.3</td>\n",
       "      <td>143.55</td>\n",
       "      <td>143.80</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3639 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date    open   high     low   close  value\n",
       "32761  2024-05-10 10:00:00  154.35  154.5  153.45  154.10     66\n",
       "32762  2024-05-10 11:00:00  154.10  154.8  153.25  154.15     66\n",
       "32763  2024-05-10 12:00:00  154.15  154.3  153.25  154.15     66\n",
       "32764  2024-05-10 13:00:00  154.15  155.2  153.00  155.05     66\n",
       "32765  2024-05-10 14:00:00  155.05  155.4  153.10  153.30     66\n",
       "...                    ...     ...    ...     ...     ...    ...\n",
       "36395  2024-10-08 20:00:00  143.35  143.9  142.35  142.95     49\n",
       "36396  2024-10-08 21:00:00  142.95  144.1  142.25  143.75     49\n",
       "36397  2024-10-08 22:00:00  143.75  144.5  143.35  144.50     49\n",
       "36398  2024-10-08 23:00:00  144.50  144.7  144.05  144.25     49\n",
       "36399  2024-10-09 00:00:00  144.25  144.3  143.55  143.80     49\n",
       "\n",
       "[3639 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df.copy().loc[int(tamanio*0.9 + 1):tamanio]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valitest = pd.concat([df_vali, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numero de horas que se utilizan en la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numhorasconst = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales Densas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿GPU detectada?: []\n"
     ]
    }
   ],
   "source": [
    "print(\"¿GPU detectada?:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de TensorFlow: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Versión de TensorFlow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        X.append(data[i:i+n_steps])\n",
    "        y.append(data[i+n_steps, 3])  \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_datos(df, numhoras):\n",
    "    data = df[['open', 'high', 'low', 'close', 'value']].values\n",
    "    X, y = create_sequences(data, numhoras)\n",
    "    X_aux = []\n",
    "    for i in X:\n",
    "        aux = []\n",
    "        for r in range(0, numhoras):\n",
    "            for elem in i[r]:\n",
    "                aux.append(elem)\n",
    "        X_aux.append(aux)       \n",
    "    X_aux = np.array(X_aux) \n",
    "    return X_aux, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalRedDensa(ytest, y_pred):\n",
    "    y_pred = y_pred.flatten()\n",
    "    suma = 0\n",
    "    n = len(y_pred)\n",
    "    for i in range(0,n):\n",
    "        suma = abs(y_pred[i] - ytest[i])/ytest[i] +  suma\n",
    "    error_medio = suma/n\n",
    "    emp = error_medio*100 # error medio en porcentaje\n",
    "    return emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opti_redes_densas(epoch_ini, epoch_fin, batch_array, numhoras, X_train, y_train, X_vali, y_vali, X_test, y_test):\n",
    "    best = 100\n",
    "    epoch_best = 0\n",
    "    bacth_best = 0\n",
    "    best_model = None\n",
    "    for e in range(epoch_ini, epoch_fin + 1):\n",
    "        for b in batch_array:\n",
    "            best_value_of_the25 = 100\n",
    "            best_model_of_the25 = None\n",
    "            for i in range(0, 25):#Número de veces que se entrena cada modelo   \n",
    "                model = Sequential()\n",
    "                model.add(Dense(64, activation='relu', input_shape=(numhoras*5,)))\n",
    "                model.add(Dense(64, activation='relu'))\n",
    "                model.add(Dense(1))\n",
    "                model.compile(optimizer='adam', loss='mape')\n",
    "                history = model.fit(X_train, y_train, epochs=e, batch_size=b, validation_data=(X_vali, y_vali), shuffle=False)\n",
    "                y_pred = model.predict(X_test)\n",
    "                valor = evalRedDensa(y_test, y_pred)\n",
    "                if valor < best_value_of_the25:\n",
    "                    best_value_of_the25 = valor\n",
    "                    best_model_of_the25 = model\n",
    "            print(\"epoch: \"+str(e)+\", batch_size: \"+str(b)+\", value: \"+str(best_value_of_the25))\n",
    "            with open('pasosdados.txt', 'w') as archivo:\n",
    "                archivo.write(\"epoch: \"+str(e)+\", batch_size: \"+str(b) +\"\\n\")\n",
    "            if best_value_of_the25 < best:\n",
    "                best = best_value_of_the25\n",
    "                epoch_best = e\n",
    "                bacth_best = b\n",
    "                cadena_guardado = \"ModelosDensosOptiMoreDataIMC/mi_modelo_denso_Opti_e\"+str(e)+\"_b\"+str(b)+\"_v\"+str(round(best_value_of_the25, 3)+\"_nh\"+str(numhoras))\n",
    "                best_model_of_the25.save(cadena_guardado+\".h5\")\n",
    "                best_model_of_the25.save(cadena_guardado+\".keras\")\n",
    "                best_model = best_model_of_the25\n",
    "    return epoch_best, bacth_best, valor, best_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opti_rd_h(inih, finh, epoch_ini, epoch_fin, batch_array):\n",
    "    best = 100\n",
    "    epoch_best = 0\n",
    "    bacth_best = 0\n",
    "    h_best = 0\n",
    "    best_model = None\n",
    "    for i in range(inih, finh+1):\n",
    "        Xtrain, ytrain = preparar_datos(df_train, i)\n",
    "        Xvali, yvali = preparar_datos(df_vali, i)\n",
    "        Xtest, ytest = preparar_datos(df_test, i)\n",
    "        valores = opti_redes_densas(epoch_ini, epoch_fin, batch_array, i, Xtrain, ytrain, Xvali, yvali, Xtest, ytest)\n",
    "        if valores[2] < best:\n",
    "            best = valores[2]\n",
    "            epoch_best = valores[0]\n",
    "            bacth_best = valores[1]\n",
    "            h_best = i\n",
    "            best_model = valores[3]\n",
    "            cadena_guardado = \"ModelosDensosOptiMoreDataIMCBest/mi_modelo_denso_Opti_e\"+str(epoch_best)+\"_b\"+str(bacth_best)+\"_h\"+str(i)+\"_v\"+str(round(best, 3)+\"_nh\"+str(i))\n",
    "            best_model.save(cadena_guardado+\".h5\")\n",
    "            best_model.save(cadena_guardado+\".keras\")\n",
    "        with open('pasosdadoshoras.txt', 'w') as archivo:\n",
    "            archivo.write(\"horas: \"+str(i)+\"\\n\")\n",
    "    return best, epoch_best, bacth_best, h_best, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raulg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802us/step - loss: 12.9824 - val_loss: 13.4089\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 782us/step - loss: 7.6837 - val_loss: 8.6074\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 844us/step - loss: 5.1047 - val_loss: 8.6145\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802us/step - loss: 17.7438 - val_loss: 25.7001\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 792us/step - loss: 7.7851 - val_loss: 12.7188\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 800us/step - loss: 5.4078 - val_loss: 7.4076\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 795us/step - loss: 12.6637 - val_loss: 18.1588\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 789us/step - loss: 6.6123 - val_loss: 9.5441\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 783us/step - loss: 5.2128 - val_loss: 6.4979\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 790us/step - loss: 16.6794 - val_loss: 20.4262\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 778us/step - loss: 6.7104 - val_loss: 9.5448\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 776us/step - loss: 5.7321 - val_loss: 6.3749\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 783us/step - loss: 14.6461 - val_loss: 23.3135\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 782us/step - loss: 8.0801 - val_loss: 11.7115\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 779us/step - loss: 5.2206 - val_loss: 7.8845\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 798us/step - loss: 19.7577 - val_loss: 28.4772\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 787us/step - loss: 8.9468 - val_loss: 11.5297\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 786us/step - loss: 5.1299 - val_loss: 7.2359\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 809us/step - loss: 23.1441 - val_loss: 32.0276\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 798us/step - loss: 9.3618 - val_loss: 14.8068\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 798us/step - loss: 5.2803 - val_loss: 9.2483\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 814us/step - loss: 17.0546 - val_loss: 22.9672\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 784us/step - loss: 8.9743 - val_loss: 11.6063\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 787us/step - loss: 5.1950 - val_loss: 7.4976\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 805us/step - loss: 11.5585 - val_loss: 19.4236\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 788us/step - loss: 7.2388 - val_loss: 13.1540\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 794us/step - loss: 6.0630 - val_loss: 8.5900\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 807us/step - loss: 13.9662 - val_loss: 21.4949\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 791us/step - loss: 7.8067 - val_loss: 11.7526\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 795us/step - loss: 5.5494 - val_loss: 7.5769\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 807us/step - loss: 17.6572 - val_loss: 21.1176\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 805us/step - loss: 7.8509 - val_loss: 12.4202\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 802us/step - loss: 6.3089 - val_loss: 8.3433\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 788us/step - loss: 14.8728 - val_loss: 24.0099\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 777us/step - loss: 8.7144 - val_loss: 12.1430\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 777us/step - loss: 5.6771 - val_loss: 7.8131\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 785us/step - loss: 22.5646 - val_loss: 18.1601\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 774us/step - loss: 7.9619 - val_loss: 11.8968\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 776us/step - loss: 5.0434 - val_loss: 9.0957\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 769us/step - loss: 14.5423 - val_loss: 16.1187\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 764us/step - loss: 6.2485 - val_loss: 9.4030\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 762us/step - loss: 4.7960 - val_loss: 6.6342\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 780us/step - loss: 13.3623 - val_loss: 20.6531\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 759us/step - loss: 7.0696 - val_loss: 7.9567\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 759us/step - loss: 5.0231 - val_loss: 5.6044\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 750us/step - loss: 20.2798 - val_loss: 29.1695\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 755us/step - loss: 10.4486 - val_loss: 10.6256\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 750us/step - loss: 5.6093 - val_loss: 3.9198\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 787us/step - loss: 17.7574 - val_loss: 22.5044\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 768us/step - loss: 10.0565 - val_loss: 10.9051\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 771us/step - loss: 4.8319 - val_loss: 5.8201\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 772us/step - loss: 14.0099 - val_loss: 29.8751\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 754us/step - loss: 8.5672 - val_loss: 15.5679\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 745us/step - loss: 6.6128 - val_loss: 8.7829\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 786us/step - loss: 21.2741 - val_loss: 22.8071\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 784us/step - loss: 8.5001 - val_loss: 11.8226\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 783us/step - loss: 5.5719 - val_loss: 10.7706\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 796us/step - loss: 16.5037 - val_loss: 26.7834\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 789us/step - loss: 9.5039 - val_loss: 15.0844\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 790us/step - loss: 5.7195 - val_loss: 8.8632\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 864us/step - loss: 16.4532 - val_loss: 22.8154\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 842us/step - loss: 7.2390 - val_loss: 12.8345\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 829us/step - loss: 5.7083 - val_loss: 9.7715\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 848us/step - loss: 21.7144 - val_loss: 22.0371\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 795us/step - loss: 9.6238 - val_loss: 11.1669\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 796us/step - loss: 4.9771 - val_loss: 7.3171\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815us/step - loss: 14.9750 - val_loss: 15.4866\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 801us/step - loss: 7.2602 - val_loss: 7.4197\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 805us/step - loss: 4.5398 - val_loss: 5.2414\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 799us/step - loss: 12.3093 - val_loss: 17.0330\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 793us/step - loss: 6.6365 - val_loss: 10.3599\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 791us/step - loss: 5.5566 - val_loss: 5.9869\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 801us/step - loss: 20.4207 - val_loss: 25.0517\n",
      "Epoch 2/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 789us/step - loss: 8.9882 - val_loss: 11.0967\n",
      "Epoch 3/3\n",
      "\u001b[1m6369/6369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 794us/step - loss: 5.4720 - val_loss: 7.3208\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step\n",
      "epoch: 3, batch_size: 4, value: 6.3026039523069635\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('float64'), dtype('<U3')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mopti_rd_h\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m46\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 11\u001b[0m, in \u001b[0;36mopti_rd_h\u001b[1;34m(inih, finh, epoch_ini, epoch_fin, batch_array)\u001b[0m\n\u001b[0;32m      9\u001b[0m Xvali, yvali \u001b[38;5;241m=\u001b[39m preparar_datos(df_vali, i)\n\u001b[0;32m     10\u001b[0m Xtest, ytest \u001b[38;5;241m=\u001b[39m preparar_datos(df_test, i)\n\u001b[1;32m---> 11\u001b[0m valores \u001b[38;5;241m=\u001b[39m \u001b[43mopti_redes_densas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_ini\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_fin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXvali\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myvali\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valores[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m<\u001b[39m best:\n\u001b[0;32m     13\u001b[0m     best \u001b[38;5;241m=\u001b[39m valores[\u001b[38;5;241m2\u001b[39m]\n",
      "Cell \u001b[1;32mIn[20], line 29\u001b[0m, in \u001b[0;36mopti_redes_densas\u001b[1;34m(epoch_ini, epoch_fin, batch_array, numhoras, X_train, y_train, X_vali, y_vali, X_test, y_test)\u001b[0m\n\u001b[0;32m     27\u001b[0m epoch_best \u001b[38;5;241m=\u001b[39m e\n\u001b[0;32m     28\u001b[0m bacth_best \u001b[38;5;241m=\u001b[39m b\n\u001b[1;32m---> 29\u001b[0m cadena_guardado \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelosDensosOptiMoreDataIMC/mi_modelo_denso_Opti_e\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_b\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(b)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_v\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_nh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(numhoras))\n\u001b[0;32m     30\u001b[0m best_model_of_the25\u001b[38;5;241m.\u001b[39msave(cadena_guardado\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m best_model_of_the25\u001b[38;5;241m.\u001b[39msave(cadena_guardado\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('float64'), dtype('<U3')) -> None"
     ]
    }
   ],
   "source": [
    "data = opti_rd_h(7, 16, 3, 15, [4, 6, 8, 12, 16, 24, 32, 46, 64, 96, 128, 256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        X.append(data[i:i+n_steps])\n",
    "        y.append(data[i+n_steps, 3])  \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_datosLSTM(df, numhoras):\n",
    "    return create_sequences(df[['open', 'high', 'low', 'close', 'value']].values, numhoras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalRedLSTM(ytest, y_pred):\n",
    "    y_pred = y_pred.flatten()\n",
    "    suma = 0\n",
    "    n = len(y_pred)\n",
    "    for i in range(0,n):\n",
    "        suma = abs(y_pred[i] - ytest[i])/ytest[i] +  suma\n",
    "    error_medio = suma/n\n",
    "    emp = error_medio*100 # error medio en porcentaje\n",
    "    return emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opti_redes_LSTM(epoch_ini, epoch_fin, batch_array, X_trainLSTM, y_trainLSTM, X_valiLSTM, y_valiLSTM, X_testLSTM, y_testLSTM, numhoras):\n",
    "    best = 100\n",
    "    epoch_best = 0\n",
    "    bacth_best = 0\n",
    "    best_model = None\n",
    "    for e in range(epoch_ini, epoch_fin + 1):\n",
    "        for b in batch_array:\n",
    "            modelLSTM = Sequential()\n",
    "            modelLSTM.add(LSTM(64, activation='relu', input_shape=(numhoras, 5)))\n",
    "            modelLSTM.add(Dense(1))\n",
    "            modelLSTM.compile(optimizer='adam', loss='mape')\n",
    "            historyLSTM = modelLSTM.fit(X_trainLSTM, y_trainLSTM, epochs=e, batch_size=b, validation_data=(X_valiLSTM, y_valiLSTM), shuffle=False)\n",
    "            y_pred = modelLSTM.predict(X_testLSTM)\n",
    "            valor = evalRedLSTM(y_testLSTM, y_pred)\n",
    "            print(\"epoch: \"+str(e)+\", batch_size: \"+str(b)+\", value: \"+str(valor))\n",
    "            if valor < best:\n",
    "                best = valor\n",
    "                epoch_best = e\n",
    "                bacth_best = b\n",
    "                best_model = modelLSTM\n",
    "                cadena_guardado = \"ModelosLSTMOptiMoreDataIMC/mi_modelo_LSTMOpti_e\"+str(e)+\"_b\"+str(b)+\"_v\"+str(round(valor, 3))\n",
    "                best_model.save(cadena_guardado+\".h5\")\n",
    "                best_model.save(cadena_guardado+\".keras\")\n",
    "    return epoch_best, bacth_best, valor, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_ARRAY = [4, 8, 12, 16, 20, 24, 28, 32, 40, 48, 64, 96, 128, 192, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opti_rLSTM_h(inih, finh, epoch_ini, epoch_fin, batch_array):\n",
    "    best = 100\n",
    "    epoch_best = 0\n",
    "    bacth_best = 0\n",
    "    h_best = 0\n",
    "    best_model = None\n",
    "    for i in range(inih, finh+1):\n",
    "        Xtrain, ytrain = preparar_datosLSTM(df_train, i)\n",
    "        Xvali, yvali = preparar_datosLSTM(df_vali, i)\n",
    "        Xtest, ytest = preparar_datosLSTM(df_test, i)\n",
    "        valores = opti_redes_LSTM(epoch_ini, epoch_fin, batch_array, Xtrain, ytrain, Xvali, yvali, Xtest, ytest, i)\n",
    "        if valores[2] < best:\n",
    "            best = valores[2]\n",
    "            epoch_best = valores[0]\n",
    "            bacth_best = valores[1]\n",
    "            h_best = i\n",
    "            best_model = valores[3]\n",
    "            cadena_guardado = \"ModelosLSTMOptiMoreDataIMCBest/mi_modelo_LSTM_Opti_e\"+str(epoch_best)+\"_b\"+str(bacth_best)+\"_h\"+str(i)+\"_v\"+str(round(best, 3))\n",
    "            best_model.save(cadena_guardado+\".h5\")\n",
    "            best_model.save(cadena_guardado+\".keras\")\n",
    "    return best, epoch_best, bacth_best, h_best, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = opti_rLSTM_h(7, 16, 3, 20, BATCH_ARRAY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
